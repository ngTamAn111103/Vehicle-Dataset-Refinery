# Th∆∞ vi·ªán
import torch
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from fastreid.config import get_cfg
from fastreid.modeling.meta_arch import build_model
from fastreid.utils.checkpoint import Checkpointer
import cv2
import faiss
import numpy as np
import time
import os
import shutil
import random
from tqdm import tqdm
import hashlib
from typing import Dict, Set, List, Tuple, Optional
import imagehash
from PIL import Image
import networkx as nx 
import json
# --- FIX L·ªñI MALLOC TR√äN MAC ---
# √âp FAISS ch·ªâ d√πng 1 lu·ªìng ƒë·ªÉ tr√°nh xung ƒë·ªôt b·ªô nh·ªõ OpenMP
faiss.omp_set_num_threads(1) 
# ------------------------------

# C·∫•u h√¨nh
TEST = True
SAMPLE_SIZE = 500

# ___Ng∆∞·ª°ng l·ªçc ·∫£nh___
# ƒê·ªô n√©t
BLUR_THRESHOLD = 90.0
# ƒê·ªô t·ªëi
DARK_THRESHOLD = 30.0
# ƒê·ªô s√°ng
BRIGHT_THRESHOLD = 220.0
# Ng∆∞·ª°ng gi·ªëng nhau c·ªßa Deep Learning
THRESHOLD_FAISS = 0.9

# ___T·ªëc ƒë·ªô___
BATCH_SIZE = 256
if TEST:
    WORKERS = 1
else:
    WORKERS = 0

# ___ƒê∆∞·ªùng d·∫´n___
# Folder cha ch·ª©a ·∫£nh (C√≥ tri·ªÉn khai ƒë·ªá quy)
INPUT_FOLDER = '/Volumes/MICRON/raw_dataset_v1.1'
# Folder ch·ª©a t·∫•t c·∫£ k·∫øt qu·∫£ ƒë·∫ßu ra (ƒê·ªÉ n·∫øu ch·∫°y tr√™n ƒë√°m m√¢y, ch·ªâ c·∫ßn zip l·∫°i r·ªìi t·∫£i v·ªÅ)
OUTPUT_BASE = '/Users/nguyentaman/Downloads/Vehicle-Dataset-Refinery/results'
# File weight (Kinh nghi·ªám) ƒë∆∞·ª£c c·∫•u h√¨nh theo m√¥ h√¨nh m·∫°ng
WEIGHTS_PATH = "configs/vehicle_weights.pth"
# File c·∫•u h√¨nh th√¥ng s·ªë k·ªπ thu·∫≠t (M·∫°ng g√¨, size ·∫£nh, s·ªë l∆∞·ª£ng class, ...)
CONFIG_FILE = "configs/vehicle_config.yaml"
# ƒê·∫ßu ra file b√°o c√°o .html
REPORT_FILE = 'cleaning_report.html'
# C√°c ƒëu√¥i file ·∫£nh 
IMAGE_EXTENSIONS = (".jpg", ".jpeg", ".png", ".gif", ".bmp", ".svg", ".webp")
# C√°c folder ph√¢n lo·∫°i
FOLDERS = ["blur", "dark", "bright", "duplicates", "similar", "output_features"]

# ___Thi·∫øt b·ªã___
if torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
elif torch.cuda.is_available():
    DEVICE = torch.device("cuda")
else:
    DEVICE = torch.device("cpu")

def setup_folders():
    """
    Ki·ªÉm tra v√† xo√° folder results c≈©
    T·∫°o c√°c folder [FOLDERS] m·ªõi
    """
    # Ki·ªÉm tra v√† xo√° folder results c≈©
    if os.path.exists(OUTPUT_BASE):
        shutil.rmtree(OUTPUT_BASE)

    # T·∫°o l·∫°i to√†n b·ªô folder results
    for folder in FOLDERS:
        os.makedirs(os.path.join(OUTPUT_BASE, folder), exist_ok=True)

def get_image_paths():
    """
    L·∫•y danh s√°ch ƒë∆∞·ªùng d·∫´n t·∫•t c·∫£ ·∫£nh trong folder
    C√≥ s·ª≠ d·ª•ng ƒë·ªá quy ƒë·ªÉ qu√©t to√†n b·ªô c√°c file con n·∫øu c√≥

    Returns:
        List[str]: M·ªói ph·∫ßn t·ª≠ l√† ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi
    """

    # Kh·ªüi t·∫°o danh s√°ch ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ªõi ·∫£nh
    all_files = []

    # Ki·ªÉm tra folder input c√≥ t·ªìn t·∫°i hay kh√¥ng
    if not os.path.exists(INPUT_FOLDER):
        print(f"‚ùå Input folder kh√¥ng t·ªìn t·∫°i: {INPUT_FOLDER}")
        return []
    
    # D√πng os.walk ƒë·ªÉ qu√©t ƒë·ªá quy (recursive) c·∫£ th∆∞ m·ª•c con
    for root, _, files in os.walk(INPUT_FOLDER):
        # Duy·ªát t·∫•t c·∫£ c√°c file l·∫•y ƒë∆∞·ª£c 
        for file in files:
            # lower() t√™n file, ki·ªÉm tra xem ƒëu√¥i file c√≥ n·∫±m trong IMAGE_EXTENSIONS kh√¥ng
            # T√™n kh√¥ng ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu b·∫±ng '.'
            if file.lower().endswith(IMAGE_EXTENSIONS) and not file.startswith('.'):
                all_files.append(os.path.abspath(os.path.join(root, file)))

    # N·∫øu ·ªü ch·∫ø ƒë·ªô TEST -> L·∫•y ng·∫´u nhi√™n SAMPLE_SIZE
    if TEST and len(all_files) > SAMPLE_SIZE:
        print(f"‚ö†Ô∏è Ch·∫ø ƒë·ªô TEST: L·∫•y ng·∫´u nhi√™n {SAMPLE_SIZE} ·∫£nh.")
        return random.sample(all_files, SAMPLE_SIZE)
    return sorted(all_files)

def scan_and_filter_quality(all_images_path: List[str] = None) -> Tuple[List[str], List[Dict]]:
    """
    Qu√©t to√†n b·ªô danh s√°ch ·∫£nh v√† l·ªçc b·ªè c√°c ·∫£nh k√©m ch·∫•t l∆∞·ª£ng (m·ªù, qu√° s√°ng, qu√° t·ªëi).

    H√†m n√†y th·ª±c hi·ªán c√°c b∆∞·ªõc:
    1. Ki·ªÉm tra ƒë·ªô n√©t (Laplacian) v√† ƒë·ªô s√°ng trung b√¨nh.
    2. N·∫øu ·∫£nh ƒê·∫†T chu·∫©n: Gi·ªØ l·∫°i trong danh s√°ch tr·∫£ v·ªÅ.
    3. N·∫øu ·∫£nh KH√îNG ƒë·∫°t chu·∫©n: Di chuy·ªÉn (ho·∫∑c copy n·∫øu TEST=True) sang th∆∞ m·ª•c ph√¢n lo·∫°i 
       t∆∞∆°ng ·ª©ng (blur, dark, bright) v√† ghi log.

    Args:
        all_images_path (List[str]): Danh s√°ch ch·ª©a ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa c√°c file ·∫£nh.
                                     M·∫∑c ƒë·ªãnh l√† None.

    Returns:
        Tuple[List[str], List[Dict]]: M·ªôt tuple ch·ª©a 2 ph·∫ßn t·ª≠:
            - clean_images (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n c√°c ·∫£nh ƒë·∫°t chu·∫©n.
            - quality_log (List[Dict]): Danh s√°ch nh·∫≠t k√Ω c√°c ·∫£nh b·ªã lo·∫°i. M·ªói ph·∫ßn t·ª≠ l√† 
              m·ªôt dict ch·ª©a keys: 'name', 'path', 'reason', 'score'.
    """
    # Khai b√°o danh s√°ch ·∫£nh ƒë·ªß ƒëi·ªÅu ki·ªán
    clean_images = []
    # Khai b√°o LOGS ƒë·ªÉ t·∫°o file b√°o c√°o
    quality_log = []
    
    print("\nüßπ [B∆∞·ªõc 1] Ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh...")
    for filepath in tqdm(all_images_path, desc="Quality Check"):
        # Ki·ªÉm tra ƒë·ªô n√©t/s√°ng/t·ªëi
        _, status, score = check_image_quality(filepath)
        
        # N·∫øu ·∫£nh ƒë·ªß ƒëi·ªÅu ki·ªán
        if status == 'ok':
            clean_images.append(filepath)
        # N·∫øu ·∫£nh kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán & ·∫£nh kh√¥ng b·ªã l·ªói
        elif status != 'error':
            try:
                # ƒê∆∞·ªùng d·∫´n t·ªõi Folder ƒë√≠ch
                target_folder = os.path.join(OUTPUT_BASE, status)
                # T√™n file
                filename = os.path.basename(filepath)
                # Gh√©p t√™n file v√† folder ƒë√≠ch
                target_path = os.path.join(target_folder, filename)
                # H√†nh ƒë·ªông: Di chuy·ªÉn ·∫£nh qua folder ph√¢n lo·∫°i
                shutil.move(filepath, target_path)

                # GHI LOG
                # filename: T√™n ·∫£nh
                # target_path: ƒê∆∞·ªùng d·∫´n ƒë√£ b·ªã di chuy·ªÉn t·ªõi
                # score: k·∫øt h·ª£p v·ªõi status.upper() cho ra ƒëi·ªÉm s·ªë c·ªßa ƒëi·ªÅu ki·ªán b·ªã lo·∫°i
                quality_log.append({'name': filename, 'path': target_path, 'reason': status.upper(), 'score': score})
            except Exception as e:
                print(f"L·ªói file {filepath}: {e}")
                
    return clean_images, quality_log

def check_image_quality(image_path: str = "") -> Tuple[str, str, float]:
    """
    ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng m·ªôt b·ª©c ·∫£nh d·ª±a tr√™n ƒë·ªô n√©t (Laplacian) v√† ƒë·ªô s√°ng trung b√¨nh.

    H√†m n√†y ƒë·ªçc ·∫£nh ·ªü ch·∫ø ƒë·ªô Grayscale ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng.

    Args:
        image_path (str): ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ªõi file ·∫£nh.

    Returns:
        Tuple[str, str, float]: B·ªô 3 gi√° tr·ªã g·ªìm:
            - image_path (str): ƒê∆∞·ªùng d·∫´n g·ªëc (tr·∫£ l·∫°i ƒë·ªÉ ti·ªán x·ª≠ l√Ω theo lu·ªìng).
            - status (str): Tr·∫°ng th√°i ph√¢n lo·∫°i, bao g·ªìm:
                * 'ok': ·∫¢nh ƒë·∫°t chu·∫©n.
                * 'blur': ·∫¢nh b·ªã m·ªù (d∆∞·ªõi ng∆∞·ª°ng BLUR_THRESHOLD).
                * 'dark': ·∫¢nh qu√° t·ªëi (d∆∞·ªõi ng∆∞·ª°ng DARK_THRESHOLD).
                * 'bright': ·∫¢nh qu√° s√°ng (tr√™n ng∆∞·ª°ng BRIGHT_THRESHOLD).
                * 'error': L·ªói kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file.
            - score (float): ƒêi·ªÉm s·ªë t∆∞∆°ng ·ª©ng (Blur score ho·∫∑c Brightness mean).
    """
    try:
        # ƒê·ªçc ·∫£nh theo mode s√°ng t·ªëi (ƒëen tr·∫Øng)
        # Gi√° tr·ªã pixel t·ª´ t·ª´ 0 ƒë·∫øn 255 ƒë·ªÉ m√¥ t·∫£ ƒë·ªô s√°ng t√¥i
        img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        
        # Tr∆∞·ªùng h·ª£p ƒë·ªçc file kh√¥ng ƒë∆∞·ª£c -> error
        if img_gray is None: 
            return image_path, 'error', 0.0

        # T√≠nh to√°n ƒë·ªô blur/n√©t c·ªßa ·∫£nh b·∫±ng ph∆∞∆°ng ph√°p Variance of Laplacian
        # 1. cv2.Laplacian: "V·∫Ω" l·∫°i c√°c ƒë∆∞·ªùng vi·ªÅn/c·∫°nh c·ªßa v·∫≠t th·ªÉ trong ·∫£nh.
        # 2. cv2.CV_64F: D√πng s·ªë th·ª±c ƒë·ªÉ gi·ªØ l·∫°i c·∫£ c√°c vi·ªÅn √Çm (vi·ªÅn t·ªëi), tr√°nh m·∫•t d·ªØ li·ªáu.
        # 3. .var(): T√≠nh ph∆∞∆°ng sai (ƒë·ªô g·∫Øt). Gi√° tr·ªã c√†ng cao -> ·∫¢nh c√†ng nhi·ªÅu vi·ªÅn s·∫Øc n√©t -> ·∫¢nh n√©t.
        blur_score = cv2.Laplacian(img_gray, cv2.CV_64F).var()

        # ƒê·ªô n√©t th·∫•p h∆°n ng∆∞·ª°ng BLUR_THRESHOLD -> blur
        if blur_score < BLUR_THRESHOLD: 
            return image_path, 'blur', blur_score

        # ƒê·ªô s√°ng trung b√¨nh c·ªßa ·∫£nh
        mean_brightness = np.mean(img_gray)
        # Tr·∫£ v·ªÅ n·∫øu qu√° t·ªëi/qu√° s√°ng -> dark/bright
        if mean_brightness < DARK_THRESHOLD: 
            return image_path, 'dark', mean_brightness
        if mean_brightness > BRIGHT_THRESHOLD: 
            return image_path, 'bright', mean_brightness

        # ·∫¢nh ƒë·ªß ƒëi·ªÅu ki·ªán
        return image_path, 'ok', blur_score
    except: 
        return image_path, 'error', 0.0

def calculate_file_hash(filepath: str, method: str = 'sha256') -> str:
    """
    T√≠nh to√°n m√£ bƒÉm (Hash) c·ªßa m·ªôt file ƒë·ªÉ l√†m 'd·∫•u v√¢n tay s·ªë'.

    H√†m ƒë·ªçc file theo ch·∫ø ƒë·ªô nh·ªã ph√¢n (binary) v√† x·ª≠ l√Ω theo t·ª´ng kh·ªëi (chunk) 
    64KB ƒë·ªÉ t·ªëi ∆∞u b·ªô nh·ªõ RAM, ƒë·∫£m b·∫£o ho·∫°t ƒë·ªông t·ªët v·ªõi c·∫£ file dung l∆∞·ª£ng l·ªõn.

    Args:
        filepath (str): ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ªõi file c·∫ßn t√≠nh hash.
        method (str, optional): Thu·∫≠t to√°n bƒÉm c·∫ßn d√πng. 
                                H·ªó tr·ª£ 'sha256' (m·∫∑c ƒë·ªãnh - an to√†n cao) ho·∫∑c 'md5' (nhanh h∆°n).

    Returns:
        str: Chu·ªói m√£ hash d·∫°ng Hexadecimal (v√≠ d·ª•: '5d41402abc4b2a76...').
             Tr·∫£ v·ªÅ None n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file.
    """
    hasher = hashlib.sha256() if method == 'sha256' else hashlib.md5()
    try:
        with open(filepath, 'rb') as f:
            for chunk in iter(lambda: f.read(65536), b""):
                hasher.update(chunk)
        return hasher.hexdigest()
    except:
        return None

def find_duplicates_by_hashing(image_paths: List[str]) -> Tuple[Set[str], List[Dict]]:
    """
    Qu√©t v√† ph√°t hi·ªán ·∫£nh tr√πng l·∫∑p b·∫±ng chi·∫øn l∆∞·ª£c Hashing ƒëa t·∫ßng (Multi-stage Hashing).

    H√†m th·ª±c hi·ªán l·ªçc qua 2 giai ƒëo·∫°n n·ªëi ti·∫øp:
    1. **L·ªçc tr√πng tuy·ªát ƒë·ªëi (SHA-256):** T√¨m c√°c file gi·ªëng h·ªát nhau t·ª´ng bit (do copy-paste).
    2. **L·ªçc tr√πng n·ªôi dung (Visual Hash):**
       - **dHash (Difference Hash):** Nh·∫°y v·ªõi c·∫•u tr√∫c gradient, ph√°t hi·ªán ·∫£nh b·ªã resize/n√©n nh·∫π.
       - **pHash (Perceptual Hash):** Nh·∫°y v·ªõi t·∫ßn s·ªë ·∫£nh, ph√°t hi·ªán ·∫£nh b·ªã bi·∫øn ƒë·ªïi m√†u s·∫Øc/√°nh s√°ng nh·∫π.

    **C∆° ch·∫ø an to√†n:**
    Trong qu√° tr√¨nh qu√©t Visual Hash, h√†m c√≥ logic ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa file (os.path.exists) 
    ƒë·ªÉ tr√°nh l·ªói "File ma" (tham chi·∫øu ƒë·∫øn m·ªôt file trong t·ª´ ƒëi·ªÉn hash nh∆∞ng file ƒë√≥ 
    ƒë√£ b·ªã x√≥a b·ªüi m·ªôt thu·∫≠t to√°n hash kh√°c ngay tr∆∞·ªõc ƒë√≥).

    Args:
        image_paths (List[str]): Danh s√°ch ch·ª©a ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa c√°c ·∫£nh ƒë·∫ßu v√†o 
                                 (ƒë√£ qua b∆∞·ªõc l·ªçc ch·∫•t l∆∞·ª£ng).

    Returns:
        Tuple[Set[str], List[Dict]]: B·ªô gi√° tr·ªã tr·∫£ v·ªÅ g·ªìm:
            - **deleted** (Set[str]): T·∫≠p h·ª£p ƒë∆∞·ªùng d·∫´n c√°c file b·ªã ƒë√°nh d·∫•u l√† tr√πng (c·∫ßn x√≥a/di chuy·ªÉn).
            - **dup_log** (List[Dict]): Danh s√°ch nh·∫≠t k√Ω chi ti·∫øt. M·ªói ph·∫ßn t·ª≠ ch·ª©a th√¥ng tin:
                * 'kept_path', 'kept_score': ·∫¢nh ƒë∆∞·ª£c gi·ªØ l·∫°i.
                * 'del_path', 'del_score': ·∫¢nh b·ªã lo·∫°i b·ªè.
                * 'reason': Thu·∫≠t to√°n ph√°t hi·ªán ('SHA-256', 'dHash', 'pHash').
    """
    hashes_sha, hashes_d, hashes_p = {}, {}, {}
    deleted = set()
    dup_log = []
    
    print("\n‚ö° [B∆∞·ªõc 2] Qu√©t tr√πng l·∫∑p Hashing...")
    
    # 1. SHA256
    for f in tqdm(image_paths, desc="SHA-256"):
        if not os.path.exists(f): # (H·∫ßu nh∆∞ kh√¥ng bao gi·ªù)
            continue
        # T√≠nh SHA-256 c·ªßa ·∫£nh
        h = calculate_file_hash(f)
        # N·∫øu m√£ SHA-256 n√†y ƒë√£ t·ªìn t·∫°i trong hashes_sha -> ·∫¢nh n√†y b·ªã l·∫∑p l·∫°i 
        if h in hashes_sha:
            # T√≠nh ƒë·ªô n√©t c·ªßa 2 ·∫£nh v√† tr·∫£ ra file c√≥ ƒëi·ªÉm th·∫•p h∆°n/ƒë√£ b·ªã xo√° (th∆∞·ªùng gi·ªëng nhau)
            del_path = process_duplicate_pair(hashes_sha[h], f, dup_log, "SHA-256")
            if del_path: 
                deleted.add(del_path)
        else: 
            hashes_sha[h] = f

    # L·ªçc b·ªè nh·ªØng ·∫£nh deleted trong image_paths ƒë·∫ßu v√†o
    remaining = [f for f in image_paths if f not in deleted]

    # 2. Visual Hash
    for f in tqdm(remaining, desc="Visual Hash"):
        if f in deleted or not os.path.exists(f): 
            continue
        try:
            # ƒê·ªçc ·∫£nh
            img = Image.open(f)
            
            # --- X·ª¨ L√ù dHASH ---
            dh = str(imagehash.dhash(img))
            # N·∫øu ·∫£nh c√≥ "dh" ƒë√£ t·ªìn t·∫°i
            if dh in hashes_d:
                # L·∫•y ·∫£nh ƒë√£ t·ªìn t·∫°i tr∆∞·ªõc
                existing_path = hashes_d[dh]
                # Ki·ªÉm tra xem file c≈© c√≥ c√≤n t·ªìn t·∫°i kh√¥ng?
                # V√¨ c√≥ th·ªÉ n√≥ ƒë√£ b·ªã xo√° b·ªüi pHash ·ªü v√≤ng l·∫∑p tr∆∞·ªõc ho·∫∑c SHA256 (th∆∞·ªùng kh√¥ng/r·∫•t √≠t c√≥ tr∆∞·ªùng h·ª£p n√†y)
                if not os.path.exists(existing_path):
                    hashes_d[dh] = f # File c≈© ch·∫øt r·ªìi, t√¥n file n√†y l√™n l√†m ch·ªß
                else:
                    # L·∫•y file ƒë√£ t·ªìn t·∫°i + file hi·ªán t·∫°i
                    # Ki·ªÉm tra file n√†o ƒëi·ªÉm th·∫•p h∆°n -> Di chuy·ªÉn v√†o folder ph√¢n lo·∫°i
                    # Tr·∫£ ra file b·ªã xo√°
                    del_path = process_duplicate_pair(existing_path, f, dup_log, "dHash")
                    if del_path: 
                        deleted.add(del_path)
                        # N·∫øu file b·ªã xo√° l√† file c≈© -> C·∫≠p nh·∫≠t l·∫°i ·∫£nh v·ªõi c√°i dh ƒë√≥
                        if del_path == existing_path: 
                            hashes_d[dh] = f
                        continue # ƒê√£ xo√° th√¨ b·ªè qua pHash
            else: 
                hashes_d[dh] = f
            
            # --- X·ª¨ L√ù pHASH ---
            ph = str(imagehash.phash(img))
            # N·∫øu ·∫£nh c√≥ "ph" ƒë√£ t·ªìn t·∫°i
            if ph in hashes_p:
                # L·∫•y ·∫£nh ƒë√£ t·ªìn t·∫°i tr∆∞·ªõc
                existing_path = hashes_p[ph]
                
                # Ki·ªÉm tra file c≈© c√≤n s·ªëng kh√¥ng?
                # C√≥ th·ªÉ n√≥ v·ª´a b·ªã xo√° b·ªüi dHash ·ªü v√†i d√≤ng code tr√™n 
                if not os.path.exists(existing_path):
                    hashes_p[ph] = f # File c≈© ch·∫øt r·ªìi, t√¥n file n√†y l√™n l√†m ch·ªß
                else:
                    # L·∫•y file ƒë√£ t·ªìn t·∫°i + file hi·ªán t·∫°i
                    # Ki·ªÉm tra file n√†o ƒëi·ªÉm th·∫•p h∆°n -> Di chuy·ªÉn v√†o folder ph√¢n lo·∫°i
                    # Tr·∫£ ra file b·ªã xo√°
                    del_path = process_duplicate_pair(existing_path, f, dup_log, "pHash")
                    if del_path: 
                        deleted.add(del_path)
                        # N·∫øu file b·ªã xo√° l√† file c≈© -> C·∫≠p nh·∫≠t l·∫°i ·∫£nh v·ªõi c√°i ph ƒë√≥
                        if del_path == existing_path: 
                            hashes_p[ph] = f
            else: 
                hashes_p[ph] = f
                
        except Exception as e: 
            print(f"Error processing {f}: {e}")
            continue
        
    return deleted, dup_log

def calculate_sharpness(image_path):
    """
    T√≠nh to√°n ƒë·ªô n√©t c·ªßa ·∫£nh b·∫±ng ph∆∞∆°ng ph√°p Variance of Laplacian.

    H√†m ƒë·ªçc ·∫£nh d∆∞·ªõi d·∫°ng Grayscale ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng, sau ƒë√≥ √°p d·ª•ng b·ªô l·ªçc 
    Laplacian ƒë·ªÉ t√¨m c·∫°nh v√† t√≠nh ph∆∞∆°ng sai (variance) c·ªßa c√°c c·∫°nh ƒë√≥.
    Gi√° tr·ªã c√†ng cao ch·ª©ng t·ªè ·∫£nh c√†ng nhi·ªÅu chi ti·∫øt s·∫Øc n√©t.

    Args:
        image_path (str): ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ªõi file ·∫£nh c·∫ßn t√≠nh to√°n.

    Returns:
        float: ƒêi·ªÉm s·ªë ƒë·ªô n√©t (Sharpness Score). 
               Tr·∫£ v·ªÅ 0.0 n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file ho·∫∑c x·∫£y ra l·ªói.
    """
    try:
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # ƒê·ªçc gray lu√¥n cho nhanh
        if img is None: 
            return 0.0
        return cv2.Laplacian(img, cv2.CV_64F).var()
    except: 
        return 0.0

def process_duplicate_pair(path_a: str, path_b: str, duplicate_log: list, reason: str) -> str:
    """
    X·ª≠ l√Ω m·ªôt c·∫∑p ·∫£nh ƒë∆∞·ª£c x√°c ƒë·ªãnh l√† tr√πng l·∫∑p: So s√°nh ƒë·ªô n√©t, gi·ªØ ·∫£nh t·ªët h∆°n
    v√† di chuy·ªÉn ·∫£nh k√©m h∆°n v√†o th∆∞ m·ª•c r√°c t∆∞∆°ng ·ª©ng.

    H√†m th·ª±c hi·ªán c√°c b∆∞·ªõc:
    1. T√≠nh ƒëi·ªÉm ƒë·ªô n√©t (Sharpness Score) c·ªßa c·∫£ 2 ·∫£nh.
    2. So s√°nh: ·∫¢nh n√†o n√©t h∆°n s·∫Ω ƒë∆∞·ª£c gi·ªØ l·∫°i (Keeper).
    3. ·∫¢nh k√©m h∆°n (Deleted) s·∫Ω b·ªã di chuy·ªÉn (move) sang th∆∞ m·ª•c 'duplicates' ho·∫∑c 'similar'
       t√πy thu·ªôc v√†o l√Ω do tr√πng l·∫∑p.
    4. Ghi l·∫°i th√¥ng tin chi ti·∫øt v√†o nh·∫≠t k√Ω (duplicate_log).

    Args:
        path_a (str): ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa ·∫£nh th·ª© nh·∫•t.
        path_b (str): ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa ·∫£nh th·ª© hai.
        duplicate_log (list): Danh s√°ch ch·ª©a dict log ƒë·ªÉ ghi l·∫°i l·ªãch s·ª≠ x√≥a.
        reason (str): L√Ω do tr√πng l·∫∑p (v√≠ d·ª•: 'SHA-256', 'dHash', 'pHash').
                      D√πng ƒë·ªÉ quy·∫øt ƒë·ªãnh folder ƒë√≠ch ('duplicates' cho SHA-256, 'similar' cho c√≤n l·∫°i).

    Returns:
        str: ƒê∆∞·ªùng d·∫´n g·ªëc c·ªßa file b·ªã x√≥a (ƒë·ªÉ c·∫≠p nh·∫≠t v√†o danh s√°ch deleted b√™n ngo√†i).
             Tr·∫£ v·ªÅ None n·∫øu c√≥ l·ªói x·∫£y ra (v√≠ d·ª• file kh√¥ng t·ªìn t·∫°i).
    """
    # Ki·ªÉm tra t·ªìn t·∫°i file (tr√°nh l·ªói n·∫øu file ƒë√£ b·ªã x√≥a b·ªüi quy tr√¨nh tr∆∞·ªõc ƒë√≥)
    if not os.path.exists(path_a) or not os.path.exists(path_b): 
        return None
    
    # 1. T√≠nh ƒëi·ªÉm ƒë·ªô n√©t
    score_a = calculate_sharpness(path_a)
    score_b = calculate_sharpness(path_b)
    
    # 2. Quy·∫øt ƒë·ªãnh gi·ªØ/x√≥a (∆Øu ti√™n gi·ªØ ·∫£nh n√©t h∆°n)
    if score_a >= score_b:
        keep, delete, score_del = path_a, path_b, score_b
        score_keep = score_a
    else:
        keep, delete, score_del = path_b, path_a, score_a
        score_keep = score_b
        
    # 3. X√°c ƒë·ªãnh th∆∞ m·ª•c ƒë√≠ch
    # N·∫øu tr√πng SHA-256 (gi·ªëng h·ªát nhau) -> folder 'duplicates'
    # N·∫øu tr√πng Hash/AI (gi·ªëng t∆∞∆°ng ƒë·ªëi) -> folder 'similar'
    folder = 'duplicates' if reason == "SHA-256" else 'similar'
    target_path = os.path.join(OUTPUT_BASE, folder, os.path.basename(delete))
    
    try:
        # 4. Di chuy·ªÉn file b·ªã lo·∫°i
        shutil.move(delete, target_path)
        
        # 5. Ghi log
        duplicate_log.append({
            'kept_path': keep, 
            'kept_name': os.path.basename(keep), 
            'kept_score': score_keep,
            'del_path': target_path, 
            'del_name': os.path.basename(delete), 
            'del_score': score_del,
            'reason': reason, 
            'del_origin': delete  # Quan tr·ªçng ƒë·ªÉ truy v·∫øt d√¢y chuy·ªÅn (A tr√πng B, B tr√πng C)
        })
        return delete  # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file ƒë√£ b·ªã x√≥a
    except Exception as e: 
        print(f"L·ªói khi di chuy·ªÉn file {delete}: {e}")
        return None

class VehicleDataset(Dataset):
    """
    L·ªõp Dataset t√πy ch·ªânh ƒë·ªÉ n·∫°p v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh xe c·ªô cho m√¥ h√¨nh Deep Learning.

    L·ªõp n√†y k·∫ø th·ª´a t·ª´ torch.utils.data.Dataset, ch·ªãu tr√°ch nhi·ªám:
    1. ƒê·ªçc ·∫£nh t·ª´ ƒë∆∞·ªùng d·∫´n file.
    2. Chuy·ªÉn ƒë·ªïi h·ªá m√†u sang RGB (ƒë·ªÉ tr√°nh l·ªói ·∫£nh x√°m/PNG 4 k√™nh).
    3. Resize v√† Chu·∫©n h√≥a (Normalize) d·ªØ li·ªáu theo chu·∫©n ImageNet.
    4. X·ª≠ l√Ω l·ªói: N·∫øu ·∫£nh h·ªèng, tr·∫£ v·ªÅ None ƒë·ªÉ DataLoader l·ªçc b·ªè sau.

    Args:
        image_paths (List[str]): Danh s√°ch c√°c ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ªõi file ·∫£nh.
    """

    def __init__(self, image_paths: List[str]):
        self.image_paths = image_paths
        
        # Pipeline bi·∫øn ƒë·ªïi ·∫£nh (Preprocessing)
        self.transform = T.Compose([
            # Resize v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh m√† Model y√™u c·∫ßu (256x256)
            T.Resize((256, 256)),
            
            # Chuy·ªÉn ·∫£nh t·ª´ d·∫°ng PIL [0, 255] sang Tensor [0.0, 1.0]
            # ƒê·ªìng th·ªùi ƒë·ªïi chi·ªÅu t·ª´ (H, W, C) sang (C, H, W) ƒë·ªÉ PyTorch hi·ªÉu
            T.ToTensor(),
            
            # Chu·∫©n h√≥a m√†u s·∫Øc theo th·ªëng k√™ c·ªßa b·ªô d·ªØ li·ªáu ImageNet
            # C√¥ng th·ª©c: input[channel] = (input[channel] - mean[channel]) / std[channel]
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def __len__(self) -> int:
        """Tr·∫£ v·ªÅ t·ªïng s·ªë l∆∞·ª£ng ·∫£nh trong dataset."""
        return len(self.image_paths)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, str]:
        """
        L·∫•y m·ªôt m·∫´u d·ªØ li·ªáu t·∫°i v·ªã tr√≠ index `idx`.

        Returns:
            Tuple[torch.Tensor, str]: 
                - Tensor ·∫£nh ƒë√£ qua x·ª≠ l√Ω (C, H, W).
                - ƒê∆∞·ªùng d·∫´n g·ªëc c·ªßa ·∫£nh.
                - Tr·∫£ v·ªÅ (None, path) n·∫øu ƒë·ªçc l·ªói.
        """
        path = self.image_paths[idx]
        try:
            # M·ªü ·∫£nh v√† √©p ki·ªÉu sang RGB (Quan tr·ªçng!)
            img = Image.open(path).convert("RGB")
            
            # √Åp d·ª•ng c√°c b∆∞·ªõc transform ƒë√£ ƒë·ªãnh nghƒ©a ·ªü __init__
            return self.transform(img), path
        except Exception as e:
            print(f"L·ªói ƒë·ªçc ·∫£nh {path}: {e}")
            # Tr·∫£ v·ªÅ None ƒë·ªÉ h√†m collate_fn l·ªçc b·ªè sau n√†y
            return None, path
        
def collate_fn(batch: List[Optional[Tuple[torch.Tensor, str]]]) -> Tuple[Optional[torch.Tensor], Optional[List[str]]]:
    """
    H√†m gom nh√≥m (collate) t√πy ch·ªânh d√πng cho DataLoader ƒë·ªÉ x·ª≠ l√Ω c√°c m·∫´u d·ªØ li·ªáu l·ªói (None).

    H√†m n√†y ƒë√≥ng vai tr√≤ nh∆∞ m·ªôt b·ªô l·ªçc cu·ªëi c√πng tr∆∞·ªõc khi d·ªØ li·ªáu v√†o Model:
    1. Duy·ªát qua danh s√°ch `batch` th√¥ v√† lo·∫°i b·ªè c√°c ph·∫ßn t·ª≠ l√† `None` (do l·ªói ƒë·ªçc file ·ªü Dataset).
    2. N·∫øu sau khi l·ªçc kh√¥ng c√≤n ph·∫ßn t·ª≠ n√†o, tr·∫£ v·ªÅ (None, None).
    3. N·∫øu c√≤n d·ªØ li·ªáu, s·ª≠ d·ª•ng `default_collate` c·ªßa PyTorch ƒë·ªÉ ƒë√≥ng g√≥i c√°c Tensor l·∫ª th√†nh m·ªôt Batch Tensor.

    Args:
        batch (List): Danh s√°ch c√°c m·∫´u d·ªØ li·ªáu tr·∫£ v·ªÅ t·ª´ `VehicleDataset.__getitem__`. 
                      M·ªói ph·∫ßn t·ª≠ l√† m·ªôt tuple `(image_tensor, image_path)` ho·∫∑c `None`.

    Returns:
        Tuple: M·ªôt b·ªô 2 gi√° tr·ªã g·ªìm:
            - batch_tensors (torch.Tensor): Tensor 4 chi·ªÅu (Batch_Size, C, H, W).
            - batch_paths (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh t∆∞∆°ng ·ª©ng.
            - Tr·∫£ v·ªÅ (None, None) n·∫øu to√†n b·ªô batch b·ªã l·ªói.
    """
    # ... (Implementation)
    # L·ªçc b·ªè c√°c m·∫´u b·ªã None (l·ªói ƒë·ªçc ·∫£nh)
    batch = list(filter(lambda x: x[0] is not None, batch))
    # N·∫øu c·∫£ batch b·ªã l·ªói h·∫øt -> Tr·∫£ v·ªÅ None
    if not batch: 
        return None, None
    return torch.utils.data.dataloader.default_collate(batch)

def setup_fastreid_model() -> torch.nn.Module:
    """
    Kh·ªüi t·∫°o v√† c·∫•u h√¨nh m√¥ h√¨nh FastReID t·ª´ file config v√† weights ƒë√£ chu·∫©n b·ªã.

    Quy tr√¨nh kh·ªüi t·∫°o ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi macOS (Apple Silicon):
    1. N·∫°p c·∫•u h√¨nh m·∫∑c ƒë·ªãnh v√† ghi ƒë√® b·∫±ng file YAML t√πy ch·ªânh (vehicle_config.yaml).
    2. √âp m√¥ h√¨nh kh·ªüi t·∫°o tr√™n CPU tr∆∞·ªõc ƒë·ªÉ v∆∞·ª£t qua c∆° ch·∫ø ki·ªÉm tra CUDA c·ªßa FastReID.
    3. X√¢y d·ª±ng ki·∫øn tr√∫c m·∫°ng (Backbone + Head).
    4. N·∫°p tr·ªçng s·ªë (Weights) ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn (.pth).
    5. Chuy·ªÉn m√¥ h√¨nh sang ch·∫ø ƒë·ªô ƒë√°nh gi√° (Eval) v√† ƒë·∫©y sang thi·∫øt b·ªã tƒÉng t·ªëc (MPS/GPU).

    Returns:
        torch.nn.Module: M√¥ h√¨nh Deep Learning ƒë√£ s·∫µn s√†ng ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng.
                         (S·∫Ω t·ª± ƒë·ªông tho√°t ch∆∞∆°ng tr√¨nh n·∫øu kh√¥ng t√¨m th·∫•y file weights).
    """
    # 1. L·∫•y m·ªôt b·∫£n c·∫•u h√¨nh "tr·∫Øng" ch·ª©a h√†ng trƒÉm tham s·ªë m·∫∑c ƒë·ªãnh c·ªßa th∆∞ vi·ªán FastReID.
    cfg = get_cfg()
    
    # 2. ƒê·ªçc file CONFIG_FILE v√† ghi ƒë√® l√™n b·∫£n m·∫∑c ƒë·ªãnh.
    # B∆∞·ªõc n√†y n·∫°p c√°c tham s·ªë nh∆∞: ResNet50, IBN=True, Input=256x256...
    cfg.merge_from_file(CONFIG_FILE)
    
    # M·∫πo: ƒê·∫∑t device='cpu' trong config ƒë·ªÉ ƒë√°nh l·ª´a FastReID b·ªè qua ki·ªÉm tra CUDA
    # WORKAROUND: Force CPU build to bypass CUDA check on Mac.
    cfg.MODEL.DEVICE = "cpu"
    
    # 3. X√¢y d·ª±ng khung model (ki·∫øn tr√∫c) d·ª±a tr√™n config
    model = build_model(cfg)
    
    # 4. N·∫°p "ki·∫øn th·ª©c" (Weights) t·ª´ file .pth v√†o khung model
    if os.path.exists(WEIGHTS_PATH):
        Checkpointer(model).load(WEIGHTS_PATH)
    else:
        print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file weights.")
        exit()
        
    # 5. Chuy·ªÉn sang ch·∫ø ƒë·ªô ƒë√°nh gi√° (Eval mode)
    # T·∫Øt c√°c l·ªõp Dropout, Batch Norm dynamic ƒë·ªÉ k·∫øt qu·∫£ c·ªë ƒë·ªãnh
    model.eval()
    
    # 6. ƒê·∫©y to√†n b·ªô model sang thi·∫øt b·ªã th·ª±c t·∫ø (Mac MPS ho·∫∑c GPU)
    model.to(DEVICE) 
    return model

def extract_features(clean_images: List[str]) -> Tuple[np.ndarray, List[str]]:
    """
    Tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng (Embeddings) t·ª´ danh s√°ch ·∫£nh s·ª≠ d·ª•ng m√¥ h√¨nh Deep Learning (FastReID).
    (ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ b·∫±ng c√°ch c·∫•p ph√°t tr∆∞·ªõc ma tr·∫≠n k·∫øt qu·∫£)

    Quy tr√¨nh th·ª±c hi·ªán:
    1. S·∫Øp x·∫øp v√† l·ªçc tr√πng danh s√°ch ƒë·∫ßu v√†o ƒë·ªÉ ƒë·∫£m b·∫£o ch·ªâ s·ªë (Index) c·ªë ƒë·ªãnh.
    2. Ch·∫°y m√¥ h√¨nh theo c∆° ch·∫ø Batch Processing (x·ª≠ l√Ω h√†ng lo·∫°t) ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô.
    3. Flatten (l√†m ph·∫≥ng) c√°c tensor ƒë·∫ßu ra v·ªÅ d·∫°ng 2D (N, D).
    4. Th·ª±c hi·ªán chu·∫©n h√≥a L2 (L2 Normalization) ngay l·∫≠p t·ª©c (B∆∞·ªõc quan tr·ªçng ƒë·ªÉ t√≠nh Cosine Similarity).
    5. L∆∞u tr·ªØ backup 2 file `features.npy` v√† `paths.npy` xu·ªëng ·ªï c·ª©ng.

    Args:
        clean_images (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa c√°c ·∫£nh c·∫ßn tr√≠ch xu·∫•t.

    Returns:
        Tuple[np.ndarray, List[str]]: B·ªô gi√° tr·ªã g·ªìm:
            - final_feats (np.ndarray): Ma tr·∫≠n c√°c vector ƒë·∫∑c tr∆∞ng (float32), k√≠ch th∆∞·ªõc (S·ªë ·∫£nh, S·ªë chi·ªÅu).
            - all_paths (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh t∆∞∆°ng ·ª©ng 1-1 v·ªõi c√°c d√≤ng trong ma tr·∫≠n.
            Tr·∫£ v·ªÅ (None, None) n·∫øu qu√° tr√¨nh tr√≠ch xu·∫•t th·∫•t b·∫°i ho·∫∑c kh√¥ng c√≥ ·∫£nh.
    """
    print(f'‚ú® [B∆∞·ªõc 3] Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng Deep Learning ({len(clean_images)} ·∫£nh)...')
    
    # S·∫Øp x·∫øp l·∫°i ds ƒë·∫ßu v√†o ƒë·ªÉ c√°c l·∫ßn ch·∫°y l√† 1 k·∫øt qu·∫£ 
    clean_images = sorted(list(set(clean_images)))
    num_images = len(clean_images) # (Code m·ªõi: C·∫ßn s·ªë l∆∞·ª£ng ƒë·ªÉ t·∫°o ma tr·∫≠n r·ªóng)
    
    model = setup_fastreid_model()
    # Ch·ª©a danh s√°ch c√°c ƒë∆∞·ªùng d·∫´n ·∫£nh (clean_images) v√† quy tr√¨nh x·ª≠ l√Ω t·ª´ng ·∫£nh l·∫ª (ƒë·ªçc ·∫£nh -> resize -> normalize). Nh∆∞ng l√∫c n√†y n√≥ ch∆∞a l√†m g√¨ c·∫£, ch·ªâ ƒë·ª©ng y√™n ch·ªù l·ªánh.
    dataset = VehicleDataset(clean_images)
    
    # DataLoader ƒëi·ªÅu WORKERS nh√¢n vi√™n ch·∫°y v√†o Kho (Dataset), l·∫•y ra BATCH_SIZE ·∫£nh theo ƒë√∫ng th·ª© t·ª± danh s√°ch. N·∫øu g·∫∑p ·∫£nh l·ªói, h√†m collate_fn s·∫Ω lo·∫°i b·ªè n√≥. Sau ƒë√≥ ƒë√≥ng g√≥i l·∫°i v√† chuy·ªÉn v√†o Model ƒë·ªÉ x·ª≠ l√Ω.
    dataloader = DataLoader(
        dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, # ƒêang tr√≠ch xu·∫•t ƒë·∫∑c tr·ª©ng --> Kh√¥ng x√°o tr·ªôn, ƒë·ªçc tu·∫ßn t·ª±
        num_workers=WORKERS, 
        collate_fn=collate_fn # collate_fn: ƒê√≥ng g√≥i ·∫£nh th√†nh batch, n·∫øu None -> lo·∫°i b·ªè ra
    )
    
    # --- [CODE M·ªöI] T·ªêI ∆ØU B·ªò NH·ªö: C·∫•p ph√°t tr∆∞·ªõc v√πng nh·ªõ c·ªë ƒë·ªãnh ---
    # T·∫°i sao? Code c≈© d√πng list.append() g√¢y ph√¢n m·∫£nh RAM khi d·ªØ li·ªáu l·ªõn (100k ·∫£nh).
    # Gi·∫£i ph√°p: T·∫°o s·∫µn c√°i th√πng ch·ª©a v·ª´a kh√≠t (Pre-allocation).
    # np.zeros: T·∫°o ma tr·∫≠n to√†n s·ªë 0.
    # (num_images, 2048): K√≠ch th∆∞·ªõc (s·ªë ·∫£nh, ƒë·ªô d√†i vector ResNet50).
    # dtype='float32': ƒê·ªãnh d·∫°ng s·ªë th·ª±c nh·∫π, chu·∫©n cho FAISS.
    features_matrix = np.zeros((num_images, 2048), dtype='float32')
    all_paths = []
    
    print("--> ƒêang ch·∫°y Model...")
    start_idx = 0 # Con tr·ªè ƒë√°nh d·∫•u v·ªã tr√≠ b·∫Øt ƒë·∫ßu ƒëi·ªÅn d·ªØ li·ªáu
    
    with torch.no_grad():
        # Duy·ªát t·ª´ng l√¥ ·∫£nh
        for imgs, paths in tqdm(dataloader, desc="Embedding"):
            # V√¨ collate_fn c√≥ th·ªÉ tr·∫£ v·ªÅ (None, None) n√™n ph·∫£i check k·ªπ
            if imgs is None: continue
                
            imgs = imgs.to(DEVICE)
            feats = model(imgs)
            
            if len(feats.shape) > 2: 
                # √âp d·∫πp (Flatten) kh·ªëi d·ªØ li·ªáu th·ª´a chi·ªÅu v·ªÅ d·∫°ng chu·∫©n 2 chi·ªÅu
                # FAISS ·ªü b∆∞·ªõc sau ch·ªâ hi·ªÉu ma tr·∫≠n 2 chi·ªÅu -> Ph·∫£i √©p d·∫πp n√≥ v·ªÅ (s·ªë ·∫£nh, s·ªë chi·ªÅu vector)
                # feats.size(0): Gi·ªØ nguy√™n s·ªë l∆∞·ª£ng ·∫£nh (batch_size)
                feats = feats.view(feats.size(0), -1)
            
            # Khi t√≠nh to√°n, bi·∫øn feats ƒëang n·∫±m tr√™n VRAM c·ªßa GPU
            # .cpu(): copy d·ªØ li·ªáu ƒë√≥ t·ª´ card ƒë·ªì h·ªça v·ªÅ l·∫°i RAM h·ªá th·ªëng (CPU) ƒë·ªÉ chu·∫©n b·ªã l∆∞u tr·ªØ.
            # .numpy(): ƒê·ªïi ƒë·ªãnh d·∫°ng Tensor sang Numpy --> ƒë·ªÉ l∆∞u file .npy --> cho FAISS ƒë·ªçc hi·ªÉu
            batch_feats = feats.cpu().numpy()
            
            # L·∫•y k√≠ch th∆∞·ªõc th·ª±c t·∫ø c·ªßa batch hi·ªán t·∫°i (th∆∞·ªùng l√† 128, nh∆∞ng batch cu·ªëi c√≥ th·ªÉ √≠t h∆°n)
            batch_size = batch_feats.shape[0]
            
            # --- [CODE M·ªöI] ƒêI·ªÄN TR·ª∞C TI·∫æP V√ÄO MA TR·∫¨N L·ªöN ---
            # T√≠nh to√°n v·ªã tr√≠ k·∫øt th√∫c: T·ª´ start_idx ƒë·∫øn end_idx
            end_idx = start_idx + batch_size
            
            # G√°n d·ªØ li·ªáu batch v√†o ƒë√∫ng v·ªã tr√≠ trong ma tr·∫≠n l·ªõn ƒë√£ t·∫°o s·∫µn
            # Thay v√¨ n·ªëi ƒëu√¥i (append) t·ªën k√©m, ta ƒëi·ªÅn v√†o ch·ªó tr·ªëng
            features_matrix[start_idx:end_idx, :] = batch_feats
            
            # L∆∞u paths (List string nh·∫π n√™n append ƒë∆∞·ª£c, kh√¥ng c·∫ßn t·ªëi ∆∞u nh∆∞ ma tr·∫≠n s·ªë)
            all_paths.extend(paths)
            
            # C·∫≠p nh·∫≠t con tr·ªè b·∫Øt ƒë·∫ßu cho v√≤ng l·∫∑p sau
            start_idx = end_idx
            
    # [CODE M·ªöI] Ki·ªÉm tra xem c√≥ ·∫£nh n√†o b·ªã l·ªói (None) d·∫´n ƒë·∫øn ma tr·∫≠n b·ªã th·ª´a d√≤ng 0 ·ªü cu·ªëi kh√¥ng
    # N·∫øu s·ªë l∆∞·ª£ng path th·ª±c t·∫ø √≠t h∆°n s·ªë l∆∞·ª£ng ·∫£nh ban ƒë·∫ßu (do c√≥ ·∫£nh l·ªói), ta c·∫Øt b·ªõt ph·∫ßn th·ª´a c·ªßa ma tr·∫≠n
    if len(all_paths) < num_images:
        features_matrix = features_matrix[:len(all_paths)]
    
    if len(all_paths) == 0: 
        # features, paths tr·∫£ ra l√† None None
        return None, None
    
    # [CODE C≈® - Gi·ªØ nguy√™n logic]
    # Chuy·ªÉn ƒë·ªïi ƒë·ªô d√†i c·ªßa c√°c vector v·ªÅ 1, gi·ªØ nguy√™n h∆∞·ªõng
    # L√∫c n√†y so s√°nh 2 ·∫£nh b·∫±ng g√≥c Vector, g√≥c c√†ng nh·ªè --> 2 ·∫£nh c√†ng gi·ªëng nhau
    # L∆∞u √Ω: faiss.normalize_L2 l√†m vi·ªác tr·ª±c ti·∫øp tr√™n b·ªô nh·ªõ (In-place), kh√¥ng t·∫°o b·∫£n copy m·ªõi -> Ti·∫øt ki·ªám RAM
    faiss.normalize_L2(features_matrix)
    
    out_dir = os.path.join(OUTPUT_BASE, "output_features")
    os.makedirs(out_dir, exist_ok=True) # Th√™m d√≤ng n√†y cho an to√†n
    # L∆∞u Ma tr·∫≠n s·ªë h·ªçc ch·ª©a c√°c vector ƒë·∫∑c tr∆∞ng
    np.save(os.path.join(out_dir, "features.npy"), features_matrix)
    # M·ªôt danh s√°ch (List) c√°c ƒë∆∞·ªùng d·∫´n file ·∫£nh
    np.save(os.path.join(out_dir, "paths.npy"), all_paths)
    
    print(f"‚úÖ ƒê√£ l∆∞u features.npy ({features_matrix.shape}) v√†o {out_dir}")
    
    return features_matrix, all_paths

def cluster_and_filter_faiss(features: np.ndarray, paths: List[str], duplicate_log: List[Dict]) -> int:
    """
    Ph√¢n c·ª•m v√† l·ªçc ·∫£nh tr√πng l·∫∑p s·ª≠ d·ª•ng AI (FAISS) k·∫øt h·ª£p L√Ω thuy·∫øt ƒë·ªì th·ªã v√† Ki·ªÉm tra tr·ª±c ti·∫øp.

    Chi·∫øn l∆∞·ª£c ho·∫°t ƒë·ªông: "Gom nh√≥m r·ªông, Ki·ªÉm tra ch·∫∑t".
    1. D√πng FAISS ƒë·ªÉ t√¨m t·∫•t c·∫£ c√°c c·∫∑p ·∫£nh c√≥ n√©t t∆∞∆°ng ƒë·ªìng (Range Search).
    2. D√πng ƒê·ªì th·ªã (Graph) ƒë·ªÉ gom c√°c c·∫∑p r·ªùi r·∫°c th√†nh c√°c nh√≥m li√™n th√¥ng (Connected Components).
    3. Trong m·ªói nh√≥m, ch·ªçn ra ·∫£nh n√©t nh·∫•t l√†m "Keeper" (·∫¢nh g·ªëc).
    4. **Ki·ªÉm tra tr·ª±c ti·∫øp (Direct Check):** T√≠nh l·∫°i ƒë·ªô gi·ªëng nhau gi·ªØa Keeper v√† t·ª´ng ·∫£nh th√†nh vi√™n.
       Ch·ªâ x√≥a ·∫£nh th√†nh vi√™n n·∫øu n√≥ th·ª±c s·ª± gi·ªëng Keeper tr√™n ng∆∞·ª°ng quy ƒë·ªãnh. ƒêi·ªÅu n√†y gi√∫p tr√°nh
       l·ªói "b·∫Øc c·∫ßu" (A gi·ªëng B, B gi·ªëng C, nh∆∞ng A kh√°c C).

    Args:
        features (np.ndarray): Ma tr·∫≠n vector ƒë·∫∑c tr∆∞ng ƒë√£ chu·∫©n h√≥a L2 (Shape: N x 2048).
        paths (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh t∆∞∆°ng ·ª©ng.
        duplicate_log (List[Dict]): Danh s√°ch ƒë·ªÉ ghi nh·∫≠t k√Ω c√°c file b·ªã x√≥a.

    Returns:
        int: S·ªë l∆∞·ª£ng ·∫£nh ƒë√£ b·ªã di chuy·ªÉn sang th∆∞ m·ª•c 'similar'.
    """
    print(f"\n‚ú® [B∆∞·ªõc 5] Gom nh√≥m ·∫£nh tr√πng b·∫±ng FAISS (Threshold={THRESHOLD_FAISS} - Aggressive Mode)...")
    
    # 1. ƒê∆∞a to√†n b·ªô vector v√†o c·∫•u tr√∫c d·ªØ li·ªáu c·ªßa FAISS ƒë·ªÉ chu·∫©n b·ªã t√¨m ki·∫øm.
    # shape[1]: L√† ƒë·ªô d√†i c·ªßa vector ƒë·∫∑c tr∆∞ng (v√≠ d·ª•: 2048 con s·ªë).
    # M·ª•c ƒë√≠ch: ƒê·ªÉ khai b√°o ƒë·ªô d√†i cho FAISS
    d = features.shape[1]

    # S·ª≠ d·ª•ng IndexFlatIP. 
    # faiss: Th∆∞ vi·ªán
    # Index: c·∫•u tr√∫c d·ªØ li·ªáu
    # Flat: ph·∫≥ng (L∆∞u tr·ªØ nguy√™n b·∫£n). So s√°nh c·∫ßn t√¨m v·ªõi t·∫•t c·∫£ vector c√≤n l·∫°i
    # IP: T√≠ch v√¥ h∆∞·ªõng == ƒê·ªô t∆∞∆°ng ƒë·ªìng Cosine (G√≥c).
    # V√¨ vector ƒë√£ chu·∫©n h√≥a L2, t√≠ch v√¥ h∆∞·ªõng ch√≠nh l√† Cosine Similarity (ƒê·ªô t∆∞∆°ng ƒë·ªìng g√≥c).
    index = faiss.IndexFlatIP(d)
    # add to√†n b·ªô vector features v√†o index ƒë√£ t·∫°o
    index.add(features)
    
    # 2. Range Search: 3 m·∫£ng 1 chi·ªÅu n√©n (Compressed): lims, D, I.
    # lims(Limits): L√† m·ª•c l·ª•c ƒë·ªÉ bi·∫øt ·∫£nh th·ª© i n·∫±m t·ª´ ƒë√¢u ƒë·∫øn ƒë√¢u
    # D(Distances): Ch·ª©a to√†n b·ªô ƒëi·ªÉm s·ªë t∆∞∆°ng ƒë·ªìng (Cosine Similarity) c·ªßa t·∫•t c·∫£ c√°c c·∫∑p t√¨m th·∫•y, ƒë∆∞·ª£c n·ªëi ƒëu√¥i nhau.
    # I(Indices): Ch·ª©a ID (Index) c·ªßa nh·ªØng ·∫£nh t√¨m th·∫•y, t∆∞∆°ng ·ª©ng song song v·ªõi m·∫£ng D.
    # ==> V·ªõi m·ªói ·∫£nh, FAISS tr·∫£ v·ªÅ m·ªôt danh s√°ch c√°c "h√†ng x√≥m" (nh·ªØng ·∫£nh kh√°c gi·ªëng n√≥).
    lims, D, I = index.range_search(features, THRESHOLD_FAISS)
    # ______ Kh√∫c n√†y h·∫øt hi·ªÉu r·ªìi _______
    # 3. X√¢y d·ª±ng ƒë·ªì th·ªã
    # T·∫°o ra m·ªôt ƒë·ªì th·ªã r·ªóng.
    G = nx.Graph()
    # R·∫£i l√™n ƒë√≥ 100.000 c√°i Ch·∫•m tr√≤n (Node). M·ªói ch·∫•m ƒë·∫°i di·ªán cho 1 b·ª©c ·∫£nh (t·ª´ 0 ƒë·∫øn 99.999).
    G.add_nodes_from(range(len(paths)))

    # Duy·ªát qua t·ª´ng ·∫£nh (g·ªçi l√† ·∫£nh A)
    for i in tqdm(range(len(paths)), desc="Building Graph"):
        # 1. Tra m·ª•c l·ª•c ƒë·ªÉ t√¨m ph·∫°m vi k·∫øt qu·∫£ c·ªßa ·∫£nh A
        start = lims[i]
        end = lims[i+1]
        
        # 2. Duy·ªát qua c√°c k·∫øt qu·∫£ t√¨m th·∫•y trong ph·∫°m vi ƒë√≥
        for j in range(start, end):
            # I[j] ch√≠nh l√† ID c·ªßa ·∫£nh h√†ng x√≥m (g·ªçi l√† ·∫£nh B)
            
            if i != I[j]: # N·∫øu A kh√°c B (kh√¥ng t·ª± n·ªëi v·ªõi ch√≠nh m√¨nh)
                
                # 3. V·∫Ω m·ªôt ƒë∆∞·ªùng th·∫≥ng n·ªëi gi·ªØa A v√† B
                G.add_edge(i, I[j])

    # 4. X·ª≠ l√Ω nh√≥m (Logic: Direct Check v·ªõi Keeper)
    components = list(nx.connected_components(G))
    duplicate_groups = [c for c in components if len(c) > 1]
    
    deleted_count = 0
    sharpness_cache = {} 
    def get_sharpness(idx):
        if idx not in sharpness_cache:
            sharpness_cache[idx] = calculate_sharpness(paths[idx])
        return sharpness_cache[idx]

    # D√πng tqdm
    for component in tqdm(duplicate_groups, desc="Cleaning"):
        comp_list = list(component)
        
        # T√¨m Vua (Keeper) - ·∫¢nh n√©t nh·∫•t trong c·∫£ ƒë√°m
        comp_list.sort(key=lambda x: get_sharpness(x), reverse=True)
        keeper_idx = comp_list[0]
        keeper_vec = features[keeper_idx]
        keeper_path = paths[keeper_idx]
        keeper_score = get_sharpness(keeper_idx)
        
        # Duy·ªát qua c√°c th·∫ßn d√¢n (Candidates)
        for candidate_idx in comp_list[1:]:
            # --- SO GƒÇNG TR·ª∞C TI·∫æP ---
            # T√≠nh l·∫°i ƒë·ªô gi·ªëng nhau gi·ªØa Vua v√† Th·∫ßn d√¢n
            candidate_vec = features[candidate_idx]
            sim = np.dot(keeper_vec, candidate_vec)
            
            # N·∫øu ƒë·ªô gi·ªëng nhau l·ªõn h∆°n ng∆∞·ª°ng -> X√ìA
            if sim >= THRESHOLD_FAISS:
                del_path = paths[candidate_idx]
                target_path = os.path.join(OUTPUT_BASE, "similar", os.path.basename(del_path))
                
                try:
                    shutil.move(del_path, target_path)
                    
                    sim_percent = f"{sim * 100:.2f}%"
                    duplicate_log.append({
                        'kept_path': keeper_path, 
                        'kept_name': os.path.basename(keeper_path), 
                        'kept_score': keeper_score,
                        'del_path': target_path, 
                        'del_name': os.path.basename(del_path), 
                        'del_score': get_sharpness(candidate_idx),
                        'reason': f"AI: {sim_percent}", 
                        'del_origin': del_path
                    })
                    deleted_count += 1
                except: pass
            else:
                # Tr∆∞·ªùng h·ª£p: A gi·ªëng B (0.85), B gi·ªëng C (0.85) => A,B,C v√†o 1 nh√≥m
                # Nh∆∞ng A ch·ªâ gi·ªëng C (0.75) => KH√îNG X√ìA C.
                # C ƒë∆∞·ª£c gi·ªØ l·∫°i (s·∫Ω tr·ªü th√†nh Keeper c·ªßa m·ªôt nh√≥m kh√°c ho·∫∑c ƒë·ª©ng ƒë·ªôc l·∫≠p)
                pass

    return deleted_count

def calculate_detail_score(image_path: str) -> float:
    """
    T√≠nh ƒëi·ªÉm "ƒê·ªô chi ti·∫øt" (Detail Density) b·∫±ng thu·∫≠t to√°n Canny Edge Detection.
    
    Nguy√™n l√Ω: ƒê·∫øm s·ªë l∆∞·ª£ng ƒëi·ªÉm ·∫£nh l√† c·∫°nh (Edge Pixels). 
    - ·∫¢nh tr∆°n (s∆∞·ªùn xe): √çt c·∫°nh -> ƒêi·ªÉm th·∫•p.
    - ·∫¢nh chi ti·∫øt (bi·ªÉn s·ªë, l∆∞·ªõi t·∫£n nhi·ªát): Nhi·ªÅu c·∫°nh -> ƒêi·ªÉm cao (v√≠ d·ª• 10.000 - 50.000).

    Args:
        image_path (str): ƒê∆∞·ªùng d·∫´n file ·∫£nh.

    Returns:
        float: S·ªë l∆∞·ª£ng pixel c·∫°nh t√¨m th·∫•y.
    """
    try:
        # ƒê·ªçc ·∫£nh x√°m
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if img is None: return 0.0
        
        # D√πng Canny ƒë·ªÉ t√¨m c·∫°nh
        # Ng∆∞·ª°ng 100-200 l√† ti√™u chu·∫©n v√†ng ƒë·ªÉ l·ªçc nhi·ªÖu nh·∫π, ch·ªâ l·∫•y n√©t ch√≠nh
        edges = cv2.Canny(img, 100, 200)
        
        # ƒê·∫øm t·ªïng s·ªë ƒëi·ªÉm ·∫£nh l√† c·∫°nh (pixel m√†u tr·∫Øng = 255)
        # np.count_nonzero ƒë·∫øm s·ªë ph·∫ßn t·ª≠ kh√°c 0
        score = np.count_nonzero(edges)
        
        return float(score)
    except:
        return 0.0

def generate_html_report(duplicate_log, quality_log, output_file):
    print("üìù ƒêang t·∫°o b√°o c√°o HTML (UI/UX Ultimate Version)...")

    # --- 1. X·ª¨ L√ù D·ªÆ LI·ªÜU ---
    move_map = {entry['del_origin']: entry['kept_path'] for entry in duplicate_log}
    def find_ultimate_keeper(current_path):
        if current_path in move_map: return find_ultimate_keeper(move_map[current_path])
        return current_path

    grouped_data = {}
    for entry in duplicate_log:
        final_keeper = find_ultimate_keeper(entry['kept_path'])
        if final_keeper not in grouped_data:
            k_name = os.path.basename(final_keeper)
            k_score = entry['kept_score'] if final_keeper == entry['kept_path'] else calculate_sharpness(final_keeper)
            grouped_data[final_keeper] = {'kept_info': {'name': k_name, 'path': final_keeper, 'score': k_score}, 'deleted_list': []}
        grouped_data[final_keeper]['deleted_list'].append(entry)

    # Th·ªëng k√™
    total_quality = len(quality_log)
    total_dups = sum(len(g['deleted_list']) for g in grouped_data.values())
    
    # --- 2. HTML TEMPLATE ---
    html_head = """
    <!DOCTYPE html>
    <html lang="vi">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Dataset Cleaning Report</title>
        <link href="https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@400;500;600;700;800&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
        <style>
            :root {
                --primary: #3B82F6; --primary-light: #DBEAFE;
                --success: #10B981; --success-light: #D1FAE5;
                --warning: #F59E0B; --warning-light: #FEF3C7;
                --danger: #EF4444; --danger-light: #FEE2E2;
                --dark: #111827; --gray: #6B7280; --bg: #F9FAFB; --card: #FFFFFF;
                --shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);
                --radius: 16px;
            }
            
            /* Dark Mode Variables */
            [data-theme="dark"] {
                --bg: #0F172A; --card: #1E293B; --text: #F8FAFC; --dark: #F3F4F6;
                --shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.3);
                color: #F8FAFC;
            }

            * { box-sizing: border-box; margin: 0; padding: 0; transition: background 0.3s, color 0.3s; }
            body { font-family: 'Plus Jakarta Sans', sans-serif; background: var(--bg); color: var(--dark); padding-bottom: 100px; }
            
            /* Navbar */
            .navbar {
                position: fixed; top: 0; width: 100%; z-index: 1000;
                background: rgba(255, 255, 255, 0.8); backdrop-filter: blur(12px);
                border-bottom: 1px solid rgba(0,0,0,0.05);
                [data-theme="dark"] & { background: rgba(30, 41, 59, 0.8); border-bottom: 1px solid rgba(255,255,255,0.05); }
            }
            .nav-content {
                max-width: 1400px; margin: 0 auto; height: 70px; padding: 0 24px;
                display: flex; justify-content: space-between; align-items: center;
            }
            .logo { font-weight: 800; font-size: 20px; display: flex; align-items: center; gap: 8px; background: linear-gradient(135deg, #3B82F6, #8B5CF6); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
            .nav-menu { display: flex; gap: 8px; background: rgba(0,0,0,0.03); padding: 4px; border-radius: 12px; }
            .nav-item { 
                padding: 8px 16px; border-radius: 8px; font-size: 14px; font-weight: 600; color: var(--gray); text-decoration: none; 
                transition: all 0.2s; display: flex; align-items: center; gap: 6px;
            }
            .nav-item:hover { color: var(--primary); background: rgba(255,255,255,0.5); }
            .nav-item.active { background: var(--card); color: var(--primary); box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
            
            /* Toggle Theme */
            .theme-toggle {
                width: 40px; height: 40px; border-radius: 50%; border: none; cursor: pointer;
                background: rgba(0,0,0,0.05); display: flex; align-items: center; justify-content: center; font-size: 18px;
            }

            /* Dashboard */
            .container { max-width: 1400px; margin: 0 auto; padding: 100px 24px 40px; }
            .dashboard { 
                display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 24px; margin-bottom: 40px; 
            }
            .stat-card {
                background: var(--card); padding: 24px; border-radius: var(--radius); box-shadow: var(--shadow);
                display: flex; flex-direction: column; gap: 8px; position: relative; overflow: hidden;
            }
            .stat-card::before { content: ''; position: absolute; top: 0; left: 0; width: 4px; height: 100%; }
            .stat-icon { width: 48px; height: 48px; border-radius: 12px; display: flex; align-items: center; justify-content: center; font-size: 24px; margin-bottom: 8px; }
            .stat-value { font-size: 32px; font-weight: 800; }
            .stat-label { font-size: 14px; color: var(--gray); font-weight: 500; }

            /* Section */
            .section-header { 
                display: flex; justify-content: space-between; align-items: end; margin-bottom: 24px; 
                border-bottom: 2px solid rgba(0,0,0,0.05); padding-bottom: 16px;
            }
            .title-group h2 { font-size: 24px; font-weight: 700; display: flex; align-items: center; gap: 12px; }
            .badge-count { background: var(--primary); color: white; padding: 4px 12px; border-radius: 20px; font-size: 14px; }
            
            /* Grid Layouts */
            .grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 24px; }
            .card { 
                background: var(--card); border-radius: 16px; overflow: hidden; box-shadow: var(--shadow);
                transition: transform 0.2s; border: 1px solid rgba(0,0,0,0.03);
            }
            .card:hover { transform: translateY(-6px); box-shadow: 0 12px 20px -8px rgba(0, 0, 0, 0.1); }
            
            .card-img-box { position: relative; padding-top: 75%; overflow: hidden; background: #f1f5f9; }
            .card-img { 
                position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; 
                transition: transform 0.5s; cursor: zoom-in;
            }
            .card:hover .card-img { transform: scale(1.05); }
            
            .card-body { padding: 16px; }
            .tag { 
                display: inline-flex; align-items: center; gap: 4px; padding: 4px 10px; border-radius: 6px; 
                font-size: 11px; font-weight: 700; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 8px;
            }
            
            /* Comparison Group */
            .comp-group { 
                background: var(--card); border-radius: 24px; padding: 32px; margin-bottom: 40px; 
                box-shadow: var(--shadow); display: flex; gap: 40px; position: relative;
            }
            .comp-keeper { flex: 0 0 300px; text-align: center; border-right: 1px solid rgba(0,0,0,0.05); padding-right: 40px; position: sticky; top: 100px; height: fit-content; }
            .comp-deleted { flex: 1; }
            
            .keeper-preview { 
                width: 100%; aspect-ratio: 1/1; object-fit: contain; border-radius: 16px; 
                background: #F8FAFC; border: 1px solid rgba(0,0,0,0.05); margin: 16px 0;
                cursor: zoom-in;
            }
            
            /* Deleted Grid */
            .del-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(140px, 1fr)); gap: 16px; }
            .del-card { position: relative; border-radius: 12px; overflow: hidden; background: #000; }
            .del-card img { width: 100%; height: 100px; object-fit: cover; opacity: 0.7; transition: 0.3s; }
            .del-card:hover img { opacity: 1; }
            .del-info { 
                position: absolute; bottom: 0; left: 0; width: 100%; padding: 8px;
                background: linear-gradient(to top, rgba(0,0,0,0.8), transparent);
                color: white; font-size: 10px; display: flex; justify-content: space-between;
            }
            .del-badge { 
                position: absolute; top: 6px; right: 6px; padding: 2px 6px; 
                border-radius: 4px; font-size: 10px; font-weight: 700; color: #fff;
                box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            }

            /* Colors */
            .c-blur { background: var(--warning-light); color: var(--warning); }
            .c-dark { background: #E5E7EB; color: #374151; }
            .c-bright { background: #DBEAFE; color: #1E40AF; }
            
            .c-sha { background: #059669; }
            .c-vis { background: #0891B2; }
            .c-ai { background: #7C3AED; }

            /* Modal */
            .modal { display: none; position: fixed; z-index: 2000; inset: 0; background: rgba(0,0,0,0.95); backdrop-filter: blur(5px); cursor: zoom-out; }
            .modal-img { max-width: 90%; max-height: 90vh; margin: auto; position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); border-radius: 8px; box-shadow: 0 20px 50px rgba(0,0,0,0.5); }
        </style>
    </head>
    <body>
        <nav class="navbar">
            <div class="nav-content">
                <div class="logo"><i class="fa-solid fa-wand-magic-sparkles"></i> Neural Cleaner</div>
                <div class="nav-menu">
                    <a href="#stats" class="nav-item active"><i class="fa-solid fa-chart-pie"></i> T·ªïng quan</a>
                    <a href="#quality" class="nav-item"><i class="fa-solid fa-triangle-exclamation"></i> Ch·∫•t l∆∞·ª£ng</a>
                    <a href="#hashing" class="nav-item"><i class="fa-solid fa-fingerprint"></i> Hashing</a>
                    <a href="#ai" class="nav-item" style="color:var(--ai)"><i class="fa-solid fa-brain"></i> AI Deep Learning</a>
                </div>
                <button class="theme-toggle" onclick="toggleTheme()"><i class="fa-solid fa-moon"></i></button>
            </div>
        </nav>

        <div class="container" id="stats">
            <div class="dashboard">
                <div class="stat-card" style="border-top: 4px solid var(--warning);">
                    <div class="stat-icon c-blur"><i class="fa-solid fa-eye-slash"></i></div>
                    <span class="stat-value">{qty_bad}</span>
                    <span class="stat-label">·∫¢nh k√©m ch·∫•t l∆∞·ª£ng</span>
                </div>
                <div class="stat-card" style="border-top: 4px solid var(--success);">
                    <div class="stat-icon" style="background:var(--success-light); color:var(--success)"><i class="fa-solid fa-clone"></i></div>
                    <span class="stat-value">{hash_dups}</span>
                    <span class="stat-label">Tr√πng l·∫∑p (Hashing)</span>
                </div>
                <div class="stat-card" style="border-top: 4px solid var(--ai);">
                    <div class="stat-icon" style="background:#F3E8FF; color:var(--ai)"><i class="fa-solid fa-robot"></i></div>
                    <span class="stat-value">{ai_dups}</span>
                    <span class="stat-label">Tr√πng l·∫∑p (AI Detected)</span>
                </div>
                <div class="stat-card" style="background:linear-gradient(135deg, var(--primary), #2563EB); color:white">
                    <div class="stat-icon" style="background:rgba(255,255,255,0.2); color:white"><i class="fa-solid fa-broom"></i></div>
                    <span class="stat-value">{total_cleaned}</span>
                    <span class="stat-label" style="color:rgba(255,255,255,0.8)">T·ªïng file ƒë√£ l·ªçc</span>
                </div>
            </div>
    """

    # --- 3. SECTION: QUALITY ---
    html_quality = f"""
        <div id="quality" class="section">
            <div class="section-header">
                <div class="title-group">
                    <h2><i class="fa-solid fa-filter" style="color:var(--warning)"></i> ·∫¢nh K√©m Ch·∫•t L∆∞·ª£ng <span class="badge-count">{len(quality_log)}</span></h2>
                </div>
            </div>
            <div class="grid">
    """
    for item in quality_log:
        reason = item['reason'].lower()
        icon = "fa-moon" if "dark" in reason else ("fa-sun" if "bright" in reason else "fa-blur")
        badge_cls = f"c-{reason}"
        
        html_quality += f"""
            <div class="card">
                <div class="card-img-box">
                    <img class="card-img" data-src="{item['path']}" loading="lazy" onclick="openModal(this)">
                </div>
                <div class="card-body">
                    <span class="tag {badge_cls}"><i class="fa-solid {icon}"></i> {item['reason']}</span>
                    <div style="font-weight:600; font-size:13px; margin-bottom:4px; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">{item['name']}</div>
                    <div style="font-size:11px; color:var(--gray)">Score: <b>{item['score']:.1f}</b></div>
                </div>
            </div>
        """
    html_quality += "</div></div>"

    # --- 4. SECTION: DUPLICATES ---
    # T√°ch d·ªØ li·ªáu
    sorted_groups = sorted(grouped_data.values(), key=lambda x: len(x['deleted_list']), reverse=True)
    
    html_hash = '<div id="hashing" class="section"><div class="section-header"><div class="title-group"><h2><i class="fa-solid fa-fingerprint" style="color:var(--success)"></i> L·ªçc Hashing</h2></div></div>'
    html_ai = '<div id="ai" class="section"><div class="section-header"><div class="title-group"><h2><i class="fa-solid fa-brain" style="color:var(--ai)"></i> L·ªçc AI Deep Learning</h2></div></div>'
    
    count_hash_del = 0
    count_ai_del = 0

    for group in sorted_groups:
        kept = group['kept_info']
        deleted = group['deleted_list']
        
        hash_dels = [d for d in deleted if "AI" not in d['reason']]
        ai_dels = [d for d in deleted if "AI" in d['reason']]
        
        count_hash_del += len(hash_dels)
        count_ai_del += len(ai_dels)

        def render_block(dels, type="hash"):
            if not dels: return ""
            cards = ""
            for d in dels:
                badge_cls = "c-ai" if type == "ai" else ("c-sha" if "SHA" in d['reason'] else "c-vis")
                cards += f"""
                <div class="del-card">
                    <span class="del-badge {badge_cls}">{d['reason']}</span>
                    <img data-src="{d['del_path']}" loading="lazy" onclick="openModal(this)">
                    <div class="del-info">
                        <span><i class="fa-solid fa-trash"></i></span>
                        <span>{d['del_score']:.0f}</span>
                    </div>
                </div>
                """
            
            theme_color = "var(--ai)" if type == "ai" else "var(--success)"
            return f"""
            <div class="comp-group">
                <div class="comp-keeper">
                    <span class="tag" style="background:var(--success-light); color:var(--success); font-size:12px;"><i class="fa-solid fa-check"></i> GI·ªÆ L·∫†I (BEST)</span>
                    <img class="keeper-preview" src="{kept['path']}" onclick="openModal(this)">
                    <div style="font-weight:700;">{kept['name']}</div>
                    <div style="color:var(--gray); font-size:12px;">ƒê·ªô n√©t: {kept['score']:.1f}</div>
                </div>
                <div class="comp-deleted">
                    <h4 style="margin-bottom:16px; color:{theme_color}; display:flex; align-items:center; gap:8px;">
                        <i class="fa-solid fa-trash-can"></i> ƒê√£ lo·∫°i b·ªè {len(dels)} b·∫£n sao
                    </h4>
                    <div class="del-grid">{cards}</div>
                </div>
            </div>
            """

        html_hash += render_block(hash_dels, "hash")
        html_ai += render_block(ai_dels, "ai")

    html_hash += "</div>"
    html_ai += "</div>"

    # --- 5. FOOTER & JS ---
    html_end = """
        </div> <div id="viewer" class="modal" onclick="this.style.display='none'">
            <img class="modal-img" id="modal-img">
        </div>
        
        <script>
            // Lazy Load Images
            document.addEventListener("DOMContentLoaded", function() {
                const observer = new IntersectionObserver((entries) => {
                    entries.forEach(entry => {
                        if(entry.isIntersecting) {
                            const img = entry.target;
                            img.src = img.dataset.src;
                            observer.unobserve(img);
                        }
                    });
                });
                document.querySelectorAll('img[data-src]').forEach(img => observer.observe(img));
            });

            function openModal(el) {
                document.getElementById('viewer').style.display = 'block';
                document.getElementById('modal-img').src = el.src || el.dataset.src;
            }

            function toggleTheme() {
                const body = document.body;
                body.setAttribute('data-theme', body.getAttribute('data-theme') === 'dark' ? 'light' : 'dark');
            }
            
            // Scroll Spy
            window.onscroll = () => {
                document.querySelectorAll('.section').forEach(sec => {
                    if(window.scrollY >= (sec.offsetTop - 100)) {
                        document.querySelectorAll('.nav-item').forEach(a => a.classList.remove('active'));
                        document.querySelector('.nav-item[href*=' + sec.id + ']').classList.add('active');
                    }
                });
            };
        </script>
    </body>
    </html>
    """
    
    # Replace Placeholders
    final_html = html_head.replace("{qty_bad}", str(total_quality)) \
                          .replace("{hash_dups}", str(count_hash_del)) \
                          .replace("{ai_dups}", str(count_ai_del)) \
                          .replace("{total_cleaned}", str(total_quality + count_hash_del + count_ai_del)) \
               + html_quality + html_hash + html_ai + html_end

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(final_html)
        print(f"‚úÖ ƒê√£ t·∫°o b√°o c√°o HTML (V5 - Ultimate UI/UX) t·∫°i: {output_file}")
    except Exception as e:
        print(f"‚ùå L·ªói report: {e}")
# ================= H√ÄM MAIN (ƒêI·ªÄU PH·ªêI CH√çNH) =================
def main():
    start_time = time.time()

    # Xo√° folder results c≈© n·∫øu t·ªìn t·∫°i, t·∫°o l·∫°i folder m·ªõi
    setup_folders()

    # B∆∞·ªõc 0: L·∫•y danh s√°ch ·∫£nh
    all_images = get_image_paths()
    if all_images == []:
        return
    else:
        print(f"üîç T·ªïng ·∫£nh ƒë·∫ßu v√†o: {len(all_images)}")

    # B∆∞·ªõc 1: L·ªçc ch·∫•t l∆∞·ª£ng c·ªßa ·∫£nh
    # clean_images: ·∫£nh v∆∞·ª£t qua v√≤ng ki·ªÉm tra ch·∫•t l∆∞·ª£ng
    # quality_log: Nh·ªØng ·∫£nh kh√¥ng v∆∞·ª£t qua ki·ªÉm tra, l∆∞u l·∫°i m·ªçi th√¥ng tin -> B√°o c√°o
    clean_images, quality_log = scan_and_filter_quality(all_images_path=all_images)
    print(f"üìâ Sau l·ªçc ch·∫•t l∆∞·ª£ng c√≤n: {len(clean_images)}")

    # B2: L·ªçc Hashing
    # deleted_hashing: ·∫¢nh b·ªã xo√°
    # duplicate_log: Nh·ªØng ·∫£nh kh√¥ng v∆∞·ª£t qua ki·ªÉm tra, l∆∞u l·∫°i m·ªçi th√¥ng tin -> B√°o c√°o
    deleted_hashing, duplicate_log = find_duplicates_by_hashing(clean_images)
    # C·∫≠p nh·∫≠t danh s√°ch ·∫£nh s·∫°ch (tr·ª´ ·∫£nh ƒë√£ x√≥a do hashing)
    clean_images = [img for img in clean_images if img not in deleted_hashing]
    print(f"üìâ Sau l·ªçc Hashing c√≤n: {len(clean_images)}\n")

    # B3: Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (Deep Learning)
    # features: Vector c·ªßa danh s√°ch ·∫£nh
    # paths: ƒê∆∞·ªùng d·∫´n c·ªßa ·∫£nh
    features, paths = extract_features(clean_images)

    if features is not None and len(paths) > 0:
        # B4: L·ªçc FAISS Clustering
        deleted_faiss_count = cluster_and_filter_faiss(features, paths, duplicate_log)
        print(f"üìâ ƒê√£ l·ªçc th√™m {deleted_faiss_count} ·∫£nh tr√πng b·∫±ng AI.\n")
    else:
        print("‚ö†Ô∏è Kh√¥ng c√≥ feature n√†o ƒë·ªÉ ch·∫°y FAISS.")

    

    # B5: T·∫°o b√°o c√°o (T·ªïng h·ª£p t·∫•t c·∫£ log)
    # (B·∫°n c·∫ßn copy l·∫°i h√†m generate_html_report v√†o code n√†y ƒë·ªÉ ch·∫°y d√≤ng d∆∞·ªõi)
    generate_html_report(duplicate_log, quality_log, os.path.join(OUTPUT_BASE, REPORT_FILE))
    # L∆∞u log ra JSON ƒë·ªÉ backup
    log_data = {
    "quality_log": quality_log,
    "duplicate_log": duplicate_log,
    "stats": {
        "total_input": len(all_images),
        "clean_after_quality": len(clean_images) if 'clean_images' in locals() else 0,
    }
}
    with open(os.path.join(OUTPUT_BASE, "cleaning_log.json"), "w", encoding="utf-8") as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)
        print("‚úÖ ƒê√£ l∆∞u file log th√¥ (JSON).")
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f'\n')
    print(f"üèÅ Th·ªùi gian ch·∫°y: {elapsed_time} gi√¢y")




if __name__ == "__main__":
    main()
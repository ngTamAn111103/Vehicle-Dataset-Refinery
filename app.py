# Th∆∞ vi·ªán
import torch
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from fastreid.config import get_cfg
from fastreid.modeling.meta_arch import build_model
from fastreid.utils.checkpoint import Checkpointer
import cv2
import faiss
import numpy as np
import time
import os
import shutil
import random
from tqdm import tqdm
import hashlib
from typing import Dict, Set, List, Tuple, Optional
import imagehash
from PIL import Image
import networkx as nx 
import json
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp
import html

# ================= C·∫§U H√åNH (CONFIG) =================
TEST = False
SAMPLE_SIZE = 10000

# ___Ng∆∞·ª°ng l·ªçc ·∫£nh___
BLUR_THRESHOLD = 50.0      # ƒê·ªô n√©t
DARK_THRESHOLD = 10.0       # ƒê·ªô t·ªëi
BRIGHT_THRESHOLD = 220.0    # ƒê·ªô s√°ng
THRESHOLD_FAISS = 0.7      # Ng∆∞·ª°ng gi·ªëng nhau Deep Learning

# ___T·ªëc ƒë·ªô___
BATCH_SIZE = 128
# S·ª≠ d·ª•ng 50% s·ª©c m·∫°nh CPU 
WORKERS = max(1, int(os.cpu_count() - 2))

# ___ƒê∆∞·ªùng d·∫´n (N√™n ƒë·ªÉ tuy·ªát ƒë·ªëi)___
# INPUT_FOLDER = '/Volumes/MICRON/raw_dataset_v1.1'
INPUT_FOLDER = '/Volumes/MICRON/FriendNightClub'
OUTPUT_BASE = '/Users/nguyentaman/Downloads/ResNet-FAISS-Dedup/results2'
# ___ƒê∆∞·ªùng d·∫´n (T∆∞∆°ng ƒë·ªëi c≈©ng ƒë∆∞·ª£c)___
WEIGHTS_PATH = "configs/vehicle_weights.pth"
CONFIG_FILE = "configs/vehicle_config.yaml"
REPORT_FILE = 'cleaning_report.html'
IMAGE_EXTENSIONS = (".jpg", ".jpeg", ".png", ".gif", ".bmp", ".svg", ".webp")
FOLDERS = ["blur", "dark", "bright", "duplicates", "similar", "output_features"]

# ___Thi·∫øt b·ªã___
if torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
elif torch.cuda.is_available():
    DEVICE = torch.device("cuda")
else:
    DEVICE = torch.device("cpu")

# ================= C√ÅC H√ÄM H·ªñ TR·ª¢ (UTILS) =================
def setup_folders():
    """Ki·ªÉm tra v√† t·∫°o l·∫°i c·∫•u tr√∫c th∆∞ m·ª•c ƒë·∫ßu ra."""
    # N·∫øu t·ªìn t·∫°i th∆∞ m·ª•c ƒë·∫ßu ra -> Xo√°
    if os.path.exists(OUTPUT_BASE):
        shutil.rmtree(OUTPUT_BASE)

    # T·∫°o l·∫°i c√°c th∆∞ m·ª•c ƒë·∫ßu ra
    for folder in FOLDERS:
        os.makedirs(os.path.join(OUTPUT_BASE, folder), exist_ok=True)

def get_image_paths() -> List[str]:
    """
    L·∫•y danh s√°ch ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·∫•t c·∫£ ·∫£nh (ƒë·ªá quy).

    Returns:
        List[str]: Danh s√°ch ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi
    """
    # Danh s√°ch ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi
    all_files = []
    # ƒê·∫ßu v√†o kh√¥ng t·ªìn t·∫°i
    if not os.path.exists(INPUT_FOLDER):
        print(f"‚ùå Input folder kh√¥ng t·ªìn t·∫°i: {INPUT_FOLDER}")
        return []
    
    # ƒê·ªá quy th∆∞ m·ª•c INPUT_FOLDER
    # root: Th∆∞ m·ª•c ƒëang ƒë·ª©ng
    # files: T·∫•t c·∫£ c√°c file
    for root, _, files in os.walk(INPUT_FOLDER):
        # Duy·ªát t·∫•t c·∫£ c√°c file
        for file in files:
            # N·∫øu file c√≥ ƒëu√¥i trong IMAGE_EXTENSIONS & kh√¥ng b·∫Øt ƒë·∫ßu b·∫±ng '.'
            if file.lower().endswith(IMAGE_EXTENSIONS) and not file.startswith('.'):
                # Cho v√†o danh s√°ch tr·∫£ ra
                all_files.append(os.path.abspath(os.path.join(root, file)))

    # N·∫øu ƒëang TEST & s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªß/d∆∞
    if TEST and len(all_files) > SAMPLE_SIZE:
        print(f"‚ö†Ô∏è Ch·∫ø ƒë·ªô TEST: L·∫•y ng·∫´u nhi√™n {SAMPLE_SIZE} ·∫£nh.")
        return random.sample(all_files, SAMPLE_SIZE)
    # N·∫øu ch·∫°y th·∫≠t -> Sort t·ª´ ƒë·∫ßu
    return sorted(all_files)

def calculate_file_hash(filepath: str, method: str = 'sha256') -> str:
    """T√≠nh hash file binary."""
    hasher = hashlib.sha256() if method == 'sha256' else hashlib.md5()
    try:
        with open(filepath, 'rb') as f:
            for chunk in iter(lambda: f.read(65536), b""):
                hasher.update(chunk)
        return hasher.hexdigest()
    except:
        return None

def calculate_sharpness(image_path):
    """T√≠nh ƒë·ªô n√©t (Laplacian Variance)."""
    try:
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if img is None: 
            return 0.0
        return cv2.Laplacian(img, cv2.CV_64F).var()
    except: 
        return 0.0

def calculate_detail_score(image_path: str) -> float:
    """T√≠nh ƒëi·ªÉm chi ti·∫øt (Canny Edge)."""
    try:
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if img is None: 
            return 0.0
        edges = cv2.Canny(img, 100, 200)
        return float(np.count_nonzero(edges))
    except:
        return 0.0

def process_duplicate_pair(path_a: str, path_b: str, duplicate_log: list, reason: str) -> str:
    """X·ª≠ l√Ω c·∫∑p tr√πng l·∫∑p: Gi·ªØ ·∫£nh n√©t h∆°n, x√≥a ·∫£nh kia."""
    # N·∫øu ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi 1 trong 2 ·∫£nh kh√¥ng t·ªìn t·∫°i -> d·ª´ng
    if not os.path.exists(path_a) or not os.path.exists(path_b): 
        return None
    
    score_a = calculate_sharpness(path_a)
    score_b = calculate_sharpness(path_b)
    
    # Gi·ªØ ·∫£nh ƒëi·ªÉm cao h∆°n, xo√° ·∫£nh ƒëi·ªÉm th·∫•p h∆°n, l∆∞u ƒëi·ªÉm c·ªßa ·∫£nh b·ªã xo√° (Ghi log)
    # Gi·ªØ ƒëi·ªÉm c·ªßa ·∫£nh ƒëi·ªÉm cao h∆°n (C≈©ng ghi log)
    if score_a >= score_b:
        keep, delete, score_del = path_a, path_b, score_b
        score_keep = score_a
    else:
        keep, delete, score_del = path_b, path_a, score_a
        score_keep = score_b
    
    # Tr√πng SHA-256 l√† duplicates, c√≤n l·∫°i similar
    folder = 'duplicates' if reason == "SHA-256" else 'similar'
    target_path = os.path.join(OUTPUT_BASE, folder, os.path.basename(delete))
    
    try:
        shutil.move(delete, target_path)
        duplicate_log.append({
            'kept_path': keep, # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi file gi·ªØ l·∫°i
            'kept_name': os.path.basename(keep), # T√™n file gi·ªØ l·∫°i
            'kept_score': score_keep, # ƒêi·ªÉm file gi·ªØ l·∫°i
            'del_path': target_path, # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa b·ªã xo√°
            'del_name': os.path.basename(delete), # T√™n file b·ªã xo√°
            'del_score': score_del, # ƒêi·ªÉm c·ªßa file b·ªã xo√°
            'reason': reason, # L√Ω do xo√°
            'del_origin': delete # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa file tr∆∞·ªõc khi b·ªã xo√°
        })
        return delete
    except Exception as e: 
        print(f"L·ªói khi di chuy·ªÉn file {delete}: {e}")
        return None

# ================= B∆Ø·ªöC 1: L·ªåC CH·∫§T L∆Ø·ª¢NG (QUALITY CHECK) =================
def check_image_quality(image_path: str = "") -> Tuple[str, str, float]:
    """H√†m worker ki·ªÉm tra ch·∫•t l∆∞·ª£ng 1 ·∫£nh."""
    try:
        # L·∫•y ·∫£nh ƒëen/tr·∫Øng (B·ªè l·ªõp th·ª© 3 c·ªßa ·∫£nh)
        img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        
        # Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh
        if img_gray is None: 
            return image_path, 'error', 0.0

        # T√≠nh ƒë·ªô n√©t b·∫±ng Laplacian
        blur_score = cv2.Laplacian(img_gray, cv2.CV_64F).var()

        if blur_score < BLUR_THRESHOLD: 
            return image_path, 'blur', blur_score
        
        # ƒê·ªô s√°ng c·ªßa ·∫£nh ƒë∆∞·ª£c t√≠nh b·∫±ng trung b√¨nh c·ªông c·ªßa gi√° tr·ªã t·ª´ng pixel ch·∫°y t·ª´ 0-255 (ƒëen tr·∫Øng)
        mean_brightness = np.mean(img_gray)
        if mean_brightness < DARK_THRESHOLD: 
            return image_path, 'dark', mean_brightness
        if mean_brightness > BRIGHT_THRESHOLD: 
            return image_path, 'bright', mean_brightness

        return image_path, 'ok', blur_score
    except: 
        return image_path, 'error', 0.0

def scan_and_filter_quality(all_images_path: List[str] = None) -> Tuple[List[str], List[Dict]]:
    """ƒêa x·ª≠ l√Ω (Multiprocessing) ƒë·ªÉ l·ªçc ch·∫•t l∆∞·ª£ng ·∫£nh."""

    # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ·∫£nh ƒë·ªß ƒëi·ªÅu ki·ªán -> Tr·∫£ v·ªÅ
    clean_images = []
    # Th√¥ng tin c·ªßa ·∫£nh k√©m ch·∫•t l∆∞·ª£ng -> Tr·∫£ v·ªÅ
    quality_log = []
    
    print(f"\nüßπ [B∆∞·ªõc 1] Ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh (S·ª≠ d·ª•ng {WORKERS} nh√¢n CPU)...")
    
    with ProcessPoolExecutor(max_workers=WORKERS) as executor:
        future_results = executor.map(check_image_quality, all_images_path, chunksize=BATCH_SIZE)
        
        # Duy·ªát qua l√¥ BATCH_SIZE c·ªßa m·ªói WORKERS
        for filepath, status, score in tqdm(future_results, total=len(all_images_path), desc="Filtering"):
            if status == 'ok':
                clean_images.append(filepath)
            # ·∫¢nh kh√¥ng ƒë·ªß ch·∫•t l∆∞·ª£ng nh∆∞ng kh√¥ng ph·∫£i l·ªói
            elif status != 'error':
                try:
                    # l·∫•y 'status' l√†m ƒë√≠ch -> th∆∞ m·ª•c s·∫Ω di chuy·ªÉn ·∫£nh t·ªõi
                    target_folder = os.path.join(OUTPUT_BASE, status)
                    # T√™n file
                    filename = os.path.basename(filepath)
                    # th∆∞ m·ª•c s·∫Ω di chuy·ªÉn ·∫£nh t·ªõi + t√™n file ==> ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t∆∞∆°ng lai
                    target_path = os.path.join(target_folder, filename)
                    shutil.move(filepath, target_path)
                    # Ghi LOG l·∫°i ƒë·ªÉ report
                    quality_log.append({
                        'name': filename, # T√™n file
                        'path': target_path, # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi th·ª±c t·∫ø sau khi di chuy·ªÉn
                        'reason': status.upper(), # ƒêi·ªÅu ki·ªán b·ªã lo·∫°i
                        'score': score # S·ªë ƒëi·ªÉm 
                    })
                except Exception as e:
                    print(f"L·ªói: {e}")
    # clean_images: ·∫¢nh v∆∞·ª£t qua b√†i ki·ªÉm tra
    # quality_log: Th√¥ng tin c·ªßa ·∫£nh k√©m ch·∫•t l∆∞·ª£ng ƒë√£ b·ªã di chuy·ªÉn
    return clean_images, quality_log

# ================= B∆Ø·ªöC 2: HASHING DEDUPLICATION =================
def compute_all_hashes(filepath: str) -> Tuple[str, str, str, str]:
    """H√†m worker t√≠nh g·ªôp 3 lo·∫°i hash."""
    try:
        # SHA-256: Tr·ª´ khi coppy paste, kh√¥ng bao gi·ªù tr√πng
        sha = calculate_file_hash(filepath)
        if sha is None: 
            return filepath, None, None, None

        img = Image.open(filepath)
        d_hash = str(imagehash.dhash(img))
        p_hash = str(imagehash.phash(img))
        
        return filepath, sha, d_hash, p_hash
    except Exception as e:
        print("Kh√¥ng t√≠nh Hashing c·ªßa ·∫£nh ƒë∆∞·ª£c - {e}")
        return filepath, None, None, None

def find_duplicates_by_hashing(image_paths: List[str]) -> Tuple[Set[str], List[Dict]]:
    """L·ªçc tr√πng b·∫±ng Hashing (Map-Reduce)."""
    # L∆∞u v√¢n tay c·ªßa c√°c ·∫£nh
    hashes_sha, hashes_d, hashes_p = {}, {}, {}
    deleted = set()
    dup_log = []
    
    print(f"\n‚ö° [B∆∞·ªõc 2] Qu√©t tr√πng l·∫∑p Hashing (S·ª≠ d·ª•ng {WORKERS} nh√¢n CPU)...")

    results_cache = []
    with ProcessPoolExecutor(max_workers=WORKERS) as executor:
        future_results = executor.map(compute_all_hashes, image_paths, chunksize=BATCH_SIZE)
        
        for res in tqdm(future_results, total=len(image_paths), desc="Hashing Calculation"):
            # N·∫øu t√≠nh ƒë∆∞·ª£c SHA-256 -> Kh√¥ng l·ªói -> L∆∞u cache
            if res[1] is not None:
                results_cache.append(res)

    # Duy·ªát cache
    for f, sha, dh, ph in tqdm(results_cache, desc="Filtering Logic"):
        # 1. SHA-256
        # N·∫øu SHA-256 ƒë√£ t·ªìn t·∫°i -> 99.99% ·∫¢nh coppy paste
        if sha in hashes_sha:
            # T√≠nh to√°n ƒë·ªô n√©t -> Tr·∫£ ra ƒë∆∞·ªùng d·∫´n ·∫£nh th·∫•p ƒëi·ªÉm h∆°n
            del_path = process_duplicate_pair(hashes_sha[sha], f, dup_log, "SHA-256")
            if del_path: 
                deleted.add(del_path)
                continue 
        else:
            hashes_sha[sha] = f

        # 2. dHash
        # N·∫øu dHash ƒë√£ t·ªìn t·∫°i
        if dh in hashes_d:
            # L·∫•y ƒë∆∞·ªùng d·∫´n c·ªßa ·∫£nh c√≥ dHash ƒë√£ t·ªìn t·∫°i tr∆∞·ªõc ƒë√≥
            existing_path = hashes_d[dh]
            # Tr∆∞·ªùng h·ª£p SHA-256 move ƒëi tr∆∞·ªõc r·ªìi
            if not os.path.exists(existing_path):
                # C·∫≠p nh·∫≠t l·∫°i: V·ªõi dHash c≈©, g·∫Øn ƒë∆∞·ªùng d·∫´n ·∫£nh m·ªõi
                hashes_d[dh] = f
            # ·∫¢nh v·∫´n t·ªìn t·∫°i
            else:
                # L·∫•y ·∫£nh tr∆∞·ªõc v√† ·∫£nh hi·ªán t·∫°i ƒëi so ƒë·ªô n√©t -> tr·∫£ ra ƒë∆∞·ªùng d·∫´n c·ªßa ·∫£nh b·ªã move
                del_path = process_duplicate_pair(existing_path, f, dup_log, "dHash")
                if del_path: 
                    deleted.add(del_path)
                    # Xui sao ·∫£nh tr∆∞·ªõc k√©m ch·∫•t l∆∞·ª£ng h∆°n ·∫£nh hi·ªán t·∫°i
                    if del_path == existing_path: 
                        # C·∫≠p nh·∫≠t l·∫°i: V·ªõi dHash c≈©, g·∫Øn ƒë∆∞·ªùng d·∫´n ·∫£nh m·ªõi
                        hashes_d[dh] = f
                    continue
        else:
            hashes_d[dh] = f

        # 3. pHash
        # N·∫øu pHash ƒë√£ t·ªìn t·∫°i
        if ph in hashes_p:
            # L·∫•y ƒë∆∞·ªùng d·∫´n c·ªßa ·∫£nh c√≥ pHash ƒë√£ t·ªìn t·∫°i tr∆∞·ªõc ƒë√≥
            existing_path = hashes_p[ph]
            # Tr∆∞·ªùng h·ª£p SHA-256/dHash move ƒëi tr∆∞·ªõc r·ªìi
            if not os.path.exists(existing_path):
                # C·∫≠p nh·∫≠t l·∫°i: V·ªõi pHash c≈©, g·∫Øn ƒë∆∞·ªùng d·∫´n ·∫£nh m·ªõi
                hashes_p[ph] = f
            else:
                # L·∫•y ·∫£nh tr∆∞·ªõc v√† ·∫£nh hi·ªán t·∫°i ƒëi so ƒë·ªô n√©t -> tr·∫£ ra ƒë∆∞·ªùng d·∫´n c·ªßa ·∫£nh b·ªã move
                del_path = process_duplicate_pair(existing_path, f, dup_log, "pHash")
                if del_path: 
                    deleted.add(del_path)
                    # Xui sao ·∫£nh tr∆∞·ªõc k√©m ch·∫•t l∆∞·ª£ng h∆°n ·∫£nh hi·ªán t·∫°i
                    if del_path == existing_path: 
                        # C·∫≠p nh·∫≠t l·∫°i: V·ªõi pHash c≈©, g·∫Øn ƒë∆∞·ªùng d·∫´n ·∫£nh m·ªõi
                        hashes_p[ph] = f
        else:
            hashes_p[ph] = f
    
    # deleted: ƒê∆∞·ªùng d·∫´n ·∫£nh ƒë√£ b·ªã xo√°
    # dup_log: LOG
    return deleted, dup_log

# ================= B∆Ø·ªöC 3: DEEP LEARNING EMBEDDING =================
class VehicleDataset(Dataset):
    """
    Dataset t√πy ch·ªânh ƒë·ªÉ n·∫°p v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh xe c·ªô cho m√¥ h√¨nh Deep Learning.

    L·ªõp n√†y k·∫ø th·ª´a t·ª´ `torch.utils.data.Dataset`, ch·ªãu tr√°ch nhi·ªám chu·∫©n b·ªã d·ªØ li·ªáu 
    ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh ResNet/FastReID.

    Attributes:
        image_paths (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa ·∫£nh.
        transform (T.Compose): Chu·ªói c√°c b∆∞·ªõc bi·∫øn ƒë·ªïi ·∫£nh (Resize -> ToTensor -> Normalize).
    """

    def __init__(self, image_paths: List[str]):
        """
        Kh·ªüi t·∫°o dataset v·ªõi danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh.

        Args:
            image_paths (List[str]): Danh s√°ch c√°c ƒë∆∞·ªùng d·∫´n file ·∫£nh ƒë·∫ßu v√†o.
        """
        self.image_paths = image_paths
        self.transform = T.Compose([
            # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n c·ªßa model (th∆∞·ªùng l√† 256x256 ho·∫∑c 256x128 t√πy config)
            T.Resize((256, 256)),
            # Chuy·ªÉn ƒë·ªïi t·ª´ ·∫£nh PIL sang Tensor v√† ƒë∆∞a v·ªÅ kho·∫£ng [0, 1]
            T.ToTensor(),
            # Chu·∫©n h√≥a theo th·ªëng k√™ c·ªßa ImageNet (Mean & Std) gi√∫p model h·ªôi t·ª• nhanh h∆°n
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def __len__(self) -> int:
        """Tr·∫£ v·ªÅ t·ªïng s·ªë l∆∞·ª£ng ·∫£nh trong dataset."""
        return len(self.image_paths)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, str]:
        """
        ƒê·ªçc v√† x·ª≠ l√Ω m·ªôt ·∫£nh t·∫°i v·ªã tr√≠ index c·ª• th·ªÉ.

        Args:
            idx (int): Ch·ªâ s·ªë c·ªßa ·∫£nh trong danh s√°ch.

        Returns:
            Tuple[torch.Tensor, str]: 
                - Tensor ·∫£nh ƒë√£ qua x·ª≠ l√Ω (C, H, W).
                - ƒê∆∞·ªùng d·∫´n g·ªëc c·ªßa file ·∫£nh (ƒë·ªÉ truy v·∫øt sau n√†y).
                - Tr·∫£ v·ªÅ (None, path) n·∫øu file ·∫£nh b·ªã l·ªói kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.
        """
        path = self.image_paths[idx]
        try:
            # .convert("RGB") ƒë·ªÉ ƒë·∫£m b·∫£o ·∫£nh lu√¥n c√≥ 3 k√™nh m√†u (x·ª≠ l√Ω ·∫£nh x√°m ho·∫∑c PNG trong su·ªët)
            img = Image.open(path).convert("RGB")
            return self.transform(img), path
        except Exception as e:
            # Tr·∫£ v·ªÅ None ƒë·ªÉ collate_fn l·ªçc b·ªè
            return None, path

def collate_fn(batch: List) -> Tuple[torch.Tensor, List[str]]:
    """
    H√†m gom nh√≥m (Collate) t√πy ch·ªânh ƒë·ªÉ x·ª≠ l√Ω c√°c ·∫£nh b·ªã l·ªói khi n·∫°p d·ªØ li·ªáu.

    M·∫∑c ƒë·ªãnh DataLoader s·∫Ω l·ªói n·∫øu m·ªôt trong c√°c m·∫´u l√† None. H√†m n√†y gi√∫p l·ªçc b·ªè 
    c√°c m·∫´u None ƒë√≥ tr∆∞·ªõc khi ƒë√≥ng g√≥i th√†nh Batch.

    Args:
        batch (List): Danh s√°ch c√°c m·∫´u d·ªØ li·ªáu tr·∫£ v·ªÅ t·ª´ `__getitem__`.

    Returns:
        Tuple[torch.Tensor, List[str]]: 
            - Batch Tensor (N, C, H, W).
            - List ƒë∆∞·ªùng d·∫´n ·∫£nh t∆∞∆°ng ·ª©ng.
            - Tr·∫£ v·ªÅ (None, None) n·∫øu to√†n b·ªô batch b·ªã l·ªói.
    """
    # L·ªçc b·ªè c√°c ph·∫ßn t·ª≠ m√† img (x[0]) l√† None
    batch = list(filter(lambda x: x[0] is not None, batch))
    
    # N·∫øu l·ªçc xong m√† kh√¥ng c√≤n g√¨ (batch r·ªóng) -> B√°o hi·ªáu b·ªè qua
    if not batch: return None, None
    
    # S·ª≠ d·ª•ng h√†m collate m·∫∑c ƒë·ªãnh c·ªßa PyTorch cho c√°c d·ªØ li·ªáu s·∫°ch
    return torch.utils.data.dataloader.default_collate(batch)

def setup_fastreid_model() -> torch.nn.Module:
    """
    Kh·ªüi t·∫°o, c·∫•u h√¨nh v√† n·∫°p tr·ªçng s·ªë cho m√¥ h√¨nh FastReID.

    Quy tr√¨nh:
    1. N·∫°p c·∫•u h√¨nh t·ª´ file YAML.
    2. √Åp d·ª•ng workaround `DEVICE="cpu"` ƒë·ªÉ v∆∞·ª£t qua ki·ªÉm tra kh·ªüi t·∫°o tr√™n macOS.
    3. X√¢y d·ª±ng ki·∫øn tr√∫c m·∫°ng (Backbone + Head).
    4. N·∫°p tr·ªçng s·ªë (Weights) ƒë√£ train.
    5. Chuy·ªÉn sang ch·∫ø ƒë·ªô ƒë√°nh gi√° (Eval) v√† ƒë·∫©y sang thi·∫øt b·ªã (MPS/CUDA).

    Returns:
        torch.nn.Module: M√¥ h√¨nh Deep Learning ƒë√£ s·∫µn s√†ng ho·∫°t ƒë·ªông.
    """
    # L·∫•y c·∫•u h√¨nh m·∫∑c ƒëinh t·ª´ nh√† s·∫£n xu·∫•t
    cfg = get_cfg()
    # Ghi ƒë√® c·∫•u h√¨nh c·ªßa m√¨nh v√†o
    cfg.merge_from_file(CONFIG_FILE)
    
    # WORKAROUND: √âp kh·ªüi t·∫°o tr√™n CPU ƒë·ªÉ tr√°nh l·ªói backend CUDA tr√™n m√°y Mac
    cfg.MODEL.DEVICE = "cpu" 
    # Build model t·ª´ c·∫•u h√¨nh nh√† s·∫£n xu·∫•t + c·ªßa m√¨nh custom l·∫°i
    model = build_model(cfg)

    if os.path.exists(WEIGHTS_PATH):
        # N·∫°p ki·∫øn th·ª©c Weights v√†o
        Checkpointer(model).load(WEIGHTS_PATH)
    else:
        print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file weights t·∫°i {WEIGHTS_PATH}.")
        exit()
        
    model.eval() # T·∫Øt Dropout, Batch Norm dynamic
    model.to(DEVICE) # ƒê·∫©y sang GPU/MPS th·ª±c t·∫ø
    return model

def extract_features(clean_images: List[str]) -> Tuple[np.ndarray, List[str]]:
    """
    Tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng (Feature Embedding) t·ª´ danh s√°ch ·∫£nh.

    H√†m n√†y th·ª±c hi·ªán to√†n b·ªô quy tr√¨nh Inference:
    1. T·∫°o DataLoader v·ªõi ƒëa lu·ªìng (Workers) v√† b·ªô nh·ªõ ghim (Pin Memory).
    2. Ch·∫°y m√¥ h√¨nh ƒë·ªÉ l·∫•y vector th√¥.
    3. Chu·∫©n h√≥a vector L2 b·∫±ng NumPy (Thay th·∫ø FAISS ƒë·ªÉ tr√°nh xung ƒë·ªôt b·ªô nh·ªõ tr√™n Mac).
    4. L∆∞u tr·ªØ k·∫øt qu·∫£ `features.npy` v√† `paths.npy` xu·ªëng ·ªï c·ª©ng.

    Args:
        clean_images (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh ƒë·∫ßu v√†o.

    Returns:
        Tuple[np.ndarray, List[str]]: 
            - features_matrix: Ma tr·∫≠n vector ƒë·∫∑c tr∆∞ng (N, 2048) ki·ªÉu float32.
            - all_paths: Danh s√°ch ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ·ª©ng 1-1 v·ªõi ma tr·∫≠n.
    """
    print(f'‚ú® [B∆∞·ªõc 3] Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng Deep Learning ({len(clean_images)} ·∫£nh)...')
    
    # Sort ƒë·ªÉ t·∫•t c·∫£ l·∫ßn ch·∫°y ƒë·ªÅu gi·ªëng nhau
    clean_images = sorted(list(set(clean_images)))
    # S·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ khai b√°o c·∫•p ph√°t b·ªô nh·ªõ (ƒê·∫ßu v√†o l·ªõn m√† kh√¥ng c·∫•p ph√°t tr∆∞·ªõc d·ªÖ b·ªã crash)
    num_images = len(clean_images) 
    
    # Build model
    model = setup_fastreid_model()
    # T·∫°o 1 b·ªô dataset: ph√¢n l√¥ batch_size, resize, ...
    dataset = VehicleDataset(clean_images)
    
    # C·∫•u h√¨nh worker load ·∫£nh
    loader_workers = WORKERS
    print(f"   ‚öôÔ∏è  C·∫•u h√¨nh: {loader_workers} Workers | Device: {DEVICE}")

    dataloader = DataLoader(
        dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, # Duy·ªát tu·∫ßn t·ª±, kh√¥ng x√°o tr·ªôn ·∫£nh
        num_workers=loader_workers, 
        collate_fn=collate_fn, # B·ªô l·ªçc h√†ng l·ªói
        # pin_memory=True: ra l·ªánh cho h·ªá ƒëi·ªÅu h√†nh: "C·∫•p cho tao v√πng RAM n√†y v√† GHIM CH·∫∂T n√≥ l·∫°i, c·∫•m di chuy·ªÉn!".
        pin_memory=True if torch.cuda.is_available() or torch.backends.mps.is_available() else False, 
        # prefetch_factor=2: Trong l√∫c GPU ƒëang x·ª≠ l√Ω L√¥ 1, CPU b·∫Øt Workers ƒëi l·∫•y ·∫£nh v√† ƒë√≥ng g√≥i L√¥ 2 v√† 3 ƒë·ªÉ chu·∫©n b·ªã.
        prefetch_factor=2 if loader_workers > 0 else None,
        # persistent_workers=False: L√†m xong 1 epoch, kill process h·∫øt lu·ªìng. Epoch sau kh·ªüi t·∫°o l·∫°i -> T·ªën th·ªùi gian kh·ªüi ƒë·ªông.
        # persistent_workers=True: Gi·ªØ lu·ªìng ƒë√≥ s·ªëng, ng·ªìi ch·ªù l·ªánh ti·∫øp theo. ƒê·ª° t·ªën c√¥ng kh·ªüi t·∫°o l·∫°i ti·∫øn tr√¨nh (Process).
        persistent_workers=True if loader_workers > 0 else False,
    )
    
    # C·∫•p ph√°t tr∆∞·ªõc b·ªô nh·ªõ ƒë·ªÉ tr√°nh ph√¢n m·∫£nh.
    # np.zeros(s·ªë ·∫£nh, s·ªë chi·ªÅu vector): T·∫°o ra 1 ma tr·∫≠n v·ªõi k√≠ch th∆∞·ªõc ƒë√£ t·∫°o v·ªõi c√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh = 0 -> sau x·ª≠ l√Ω xong l√¥ n√†o ch·ªâ c·∫ßn b·ªè v√†o th√¥i
    # FAISS ƒë∆∞·ª£c build b·∫±ng C++, n√≥ ch·ªâ hi·ªÉu t·ªõi float32.
    # Fload 64 l√† l·ªói -> n√™n ph·∫£i √©n v·ªÅ f32
    features_matrix = np.zeros((num_images, 2048), dtype='float32')
    all_paths = []
    start_idx = 0 

    # T·∫Øt ch·∫ø ƒë·ªô train
    with torch.no_grad():
        # imgs: 1 l√¥ ·∫£nh
        # paths: 1 l√¥ ƒë∆∞·ªùng d·∫´n
        for imgs, paths in tqdm(dataloader, desc="Embedding"):
            if imgs is None: 
                continue
            
            # Non_blocking gi√∫p CPU kh√¥ng ph·∫£i ch·ªù GPU copy xong d·ªØ li·ªáu (ch·∫£ hi·ªÉu c√°i g√¨)
            # Gi√∫p CPU v√† vi·ªác truy·ªÅn d·ªØ li·ªáu di·ªÖn ra song song (overlap), che gi·∫•u ƒë·ªô tr·ªÖ ƒë∆∞·ªùng truy·ªÅn. (V·∫´n ko hi·ªÉu l·∫Øm)... K·ªá ƒëi
            imgs = imgs.to(DEVICE, non_blocking=True)
            # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng c·ªßa l√¥ ·∫£nh
            feats = model(imgs)
            
            # Flatten: N·∫øu ƒë·∫ßu ra l√† kh·ªëi l·∫≠p ph∆∞∆°ng (Batch, 2048, 1, 1) -> √©p d·∫πp th√†nh t·ªù gi·∫•y (Batch, 2048)
            if len(feats.shape) > 2: 
                feats = feats.view(feats.size(0), -1)
            # Chuy·ªÉn v·ªÅ CPU ƒë·ªÉ l∆∞u tr·ªØ (v√¨ RAM r·∫ª h∆°n VRAM)
            batch_feats = feats.cpu().numpy()
            batch_size = batch_feats.shape[0]
            
            # ƒêi·ªÅn v√†o ƒë√∫ng v·ªã tr√≠ ph√≤ng trong kh√°ch s·∫°n ƒë√£ x√¢y s·∫µn (features_matrix = np.zeros((num_images, 2048), dtype='float32') ·ªü tr√™n)
            end_idx = start_idx + batch_size
            features_matrix[start_idx:end_idx, :] = batch_feats
            all_paths.extend(paths)
            start_idx = end_idx
            
    # C·∫Øt b·ªè ph·∫ßn th·ª´a n·∫øu c√≥ ·∫£nh l·ªói b·ªã lo·∫°i b·ªè (C√≥ nh∆∞ng r·∫•t hi·∫øm)
    if len(all_paths) < num_images:
        features_matrix = features_matrix[:len(all_paths)]
    
    # Th∆∞·ªùng l√† b·ªã l·ªói m·ªõi d√≠nh ƒëk n√†y
    if len(all_paths) == 0: 
        return None, None
    
    # --- CHU·∫®N H√ìA L2 (NumPy Implementation) ---
    # An to√†n tuy·ªát ƒë·ªëi cho macOS, thay th·∫ø cho faiss.normalize_L2
    print("   üìê ƒêang chu·∫©n h√≥a L2 (Numpy)...")
    # T√≠nh ƒë·ªô d√†i vector
    # features_matrix: ma tr·∫≠n k√≠ch th∆∞·ªõc (·∫£nh, chi·ªÅu vector) (·ªü tr√™n)
    # axis=1: t√≠nh to√°n theo chi·ªÅu ngang (t·ª´ng d√≤ng/t·ª´ng ·∫£nh).  ==> Th√¥i kh√∫c n√†y tra google ƒëi (Nh·ª©c ƒë·∫ßu qu√°)
    norm = np.linalg.norm(features_matrix, axis=1, keepdims=True)
    # Chia vector cho ƒë·ªô d√†i (+1e-10 ƒë·ªÉ tr√°nh chia cho 0)
    features_matrix = features_matrix / (norm + 1e-10)
    features_matrix = features_matrix.astype('float32')
    
    # L∆∞u k·∫øt qu·∫£
    out_dir = os.path.join(OUTPUT_BASE, "output_features")
    os.makedirs(out_dir, exist_ok=True)
    np.save(os.path.join(out_dir, "features.npy"), features_matrix)
    np.save(os.path.join(out_dir, "paths.npy"), all_paths)
    
    return features_matrix, all_paths

# ================= B∆Ø·ªöC 5: FAISS CLUSTERING =================
def cluster_and_filter_faiss(features: np.ndarray, paths: List[str], duplicate_log: List[Dict]) -> int:
    """
    Ph√¢n c·ª•m v√† l·ªçc tr√πng l·∫∑p s·ª≠ d·ª•ng FAISS k·∫øt h·ª£p L√Ω thuy·∫øt ƒë·ªì th·ªã (Graph Theory).

    Chi·∫øn l∆∞·ª£c: "Detail Priority" (∆Øu ti√™n chi ti·∫øt).
    1. **T√¨m ki·∫øm (FAISS):** T√¨m t·∫•t c·∫£ c√°c c·∫∑p ·∫£nh c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng >= Threshold.
    2. **Gom nh√≥m (NetworkX):** X√¢y d·ª±ng ƒë·ªì th·ªã v√† t√¨m c√°c th√†nh ph·∫ßn li√™n th√¥ng (nh√≥m ·∫£nh tr√πng).
    3. **Ch·ªçn l·ªçc (Keeper Selection):** Trong m·ªói nh√≥m, ch·ªçn ·∫£nh gi·ªØ l·∫°i d·ª±a tr√™n:
       - ∆Øu ti√™n 1: ƒêi·ªÉm chi ti·∫øt cao nh·∫•t (Canny Edge) - ƒê·ªÉ gi·ªØ l·∫°i ·∫£nh r√µ bi·ªÉn s·ªë/g√≥c c·∫°nh.
       - ∆Øu ti√™n 2: Ph·∫£i ƒë·∫°t ƒë·ªô n√©t t·ªëi thi·ªÉu (Blur Threshold).
    4. **Ki·ªÉm ch·ª©ng (Re-check):** T√≠nh l·∫°i Cosine Similarity gi·ªØa Keeper v√† Candidate tr∆∞·ªõc khi x√≥a
       ƒë·ªÉ tr√°nh l·ªói b·∫Øc c·∫ßu trong ƒë·ªì th·ªã.

    Args:
        features (np.ndarray): Ma tr·∫≠n ƒë·∫∑c tr∆∞ng ƒë√£ chu·∫©n h√≥a (N, 2048).
        paths (List[str]): Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh.
        duplicate_log (List[Dict]): List ƒë·ªÉ ghi l·∫°i nh·∫≠t k√Ω x√≥a.

    Returns:
        int: S·ªë l∆∞·ª£ng ·∫£nh ƒë√£ b·ªã lo·∫°i b·ªè.
    """
    print(f"\n‚ú® [B∆∞·ªõc 5] Gom nh√≥m ·∫£nh tr√πng b·∫±ng FAISS (Threshold={THRESHOLD_FAISS} - Detail Priority)...")
    
    # 1. T·∫°o Index v√† t√¨m ki·∫øm
    # L·∫•y chi·ªÅu vector c·ªßa ƒë·∫∑c tr∆∞ng (ResNet50 == 2048)
    d = features.shape[1]
    # Khai b√°o 1 kh√¥ng gian l∆∞u tr·ªØ
    # IndexFlat: C·∫•u tr√∫c ph·∫≥ng -> L∆∞u tr·ªØ nguy√™n b·∫£n, t√¨m ki·∫øm v√©t c·∫°n -> Kh√¥ng c·∫Øt g·ªçt g√¨ (Raw)
    # IP: t√≠ch v√¥ h∆∞·ªõng
    index = faiss.IndexFlatIP(d) 
    # N·∫°p c√°c ƒë·∫∑c tr∆∞ng v√†o
    index.add(features)
    
    # Range Search: T√¨m t·∫•t c·∫£ h√†ng x√≥m trong b√°n k√≠nh Threshold
    lims, D, I = index.range_search(features, THRESHOLD_FAISS)
    
    # 2. X√¢y d·ª±ng ƒë·ªì th·ªã k·∫øt n·ªëi
    G = nx.Graph()

    # N·∫øu c√≥ 100k ·∫£nh => T·∫°o 100k node v√†o ƒë·ªì th·ªã
    G.add_nodes_from(range(len(paths)))
    
    # T√¨m h√†ng x√≥m
    for i in tqdm(range(len(paths)), desc="Building Graph"):
        start, end = lims[i], lims[i+1]
        for j in range(start, end):
            if i != I[j]: # Kh√¥ng t·ª± n·ªëi v·ªõi ch√≠nh m√¨nh
                G.add_edge(i, I[j])

    # T√¨m c√°c nh√≥m li√™n th√¥ng (Connected Components)
    components = list(nx.connected_components(G))
    # L·∫•y ra nh·ªØng c·ª•m c√≥ 2 ·∫£nh tr·ªü l√™n 
    duplicate_groups = [c for c in components if len(c) > 1]
    
    deleted_count = 0
    metrics_cache = {} 

    # H√†m helper ƒë·ªÉ l·∫•y ch·ªâ s·ªë ·∫£nh (c√≥ cache)
    def get_metrics(idx):
        if idx not in metrics_cache:
            p = paths[idx]
            metrics_cache[idx] = {
                'detail': calculate_detail_score(p),
                'sharpness': calculate_sharpness(p)
            }
        return metrics_cache[idx]

    # 3. Duy·ªát v√† l·ªçc t·ª´ng nh√≥m
    for component in tqdm(duplicate_groups, desc="AI Filtering"):
        comp_list = list(component)
        candidates = []
        
        # L·∫•y th√¥ng tin chi ti·∫øt c·ªßa t·∫•t c·∫£ ·∫£nh trong nh√≥m
        for idx in comp_list:
            m = get_metrics(idx)
            candidates.append({
                'idx': idx, 'detail': m['detail'], 'sharpness': m['sharpness']
            })
        
        # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo ƒë·ªô chi ti·∫øt
        candidates.sort(key=lambda x: x['detail'], reverse=True)
        
        # Ch·ªçn Keeper: M·∫∑c ƒë·ªãnh l√† ·∫£nh chi ti·∫øt nh·∫•t, nh∆∞ng ph·∫£i ƒë·ªß n√©t
        keeper_candidate = candidates[0] 
        for cand in candidates:
            if cand['sharpness'] >= BLUR_THRESHOLD:
                keeper_candidate = cand
                break
        
        keeper_idx = keeper_candidate['idx']
        keeper_vec = features[keeper_idx]
        keeper_path = paths[keeper_idx]
        keeper_score_log = keeper_candidate['detail'] 
        
        # Danh s√°ch c√°c ·∫£nh c·∫ßn xem x√©t x√≥a (t·∫•t c·∫£ tr·ª´ Keeper)
        duplicates_idx = [x['idx'] for x in candidates if x['idx'] != keeper_idx]
        
        for del_idx in duplicates_idx:
            # 4. Ki·ªÉm ch·ª©ng l·∫ßn cu·ªëi (Direct Check)
            candidate_vec = features[del_idx]
            sim = np.dot(keeper_vec, candidate_vec)
            
            if sim >= THRESHOLD_FAISS:
                del_path = paths[del_idx]
                target_path = os.path.join(OUTPUT_BASE, "similar", os.path.basename(del_path))
                try:
                    shutil.move(del_path, target_path)
                    
                    # Ghi log chi ti·∫øt
                    duplicate_log.append({
                        'kept_path': keeper_path, 
                        'kept_name': os.path.basename(keeper_path), 
                        'kept_score': keeper_score_log,
                        'del_path': target_path, 
                        'del_name': os.path.basename(del_path), 
                        'del_score': get_metrics(del_idx)['detail'],
                        'reason': f"AI: {sim * 100:.2f}%", 
                        'del_origin': del_path
                    })
                    deleted_count += 1
                except: pass

    return deleted_count

# ================= REPORTING =================
def generate_html_report(duplicate_log: list, quality_log: list, output_file: str = "Wow_Report.html", total_input: int = 0):
    """
    Phi√™n b·∫£n V3.1 (Fixed):
    - Fix bug: SHA-256 b·ªã nh·∫≠n nh·∫ßm l√† AI.
    - Gi·ªØ nguy√™n c√°c t√≠nh nƒÉng x·ªãn x√≤ c·ªßa V3.
    """
    
    # --- 0. HELPER: PATH TRACING & CONSTANTS ---
    redirect_map = {}
    
    # Map ƒë∆∞·ªùng d·∫´n b·ªã thay ƒë·ªïi t·ª´ duplicate log
    for item in duplicate_log:
        if 'del_origin' in item and 'del_path' in item:
            redirect_map[item['del_origin']] = item['del_path']

    def resolve_final_path(path):
        """ƒê·ªá quy t√¨m ƒë∆∞·ªùng d·∫´n cu·ªëi c√πng c·ªßa file."""
        if os.path.exists(path): return path
        current_check = path
        visited = set()
        while current_check in redirect_map:
            if current_check in visited: break
            visited.add(current_check)
            current_check = redirect_map[current_check]
            if os.path.exists(current_check): return current_check
        return path

    # --- 1. PH√ÇN LO·∫†I & TH·ªêNG K√ä CHI TI·∫æT ---
    stats = {
        "blur": 0, "dark": 0, "bright": 0, 
        "ai_dup": 0, "hash_dup": 0, 
        "total_removed": 0
    }

    categories = {
        "blur": {"data": [], "id": "section-blur", "title": "·∫¢nh M·ªù (Blur)"},
        "dark": {"data": [], "id": "section-dark", "title": "·∫¢nh T·ªëi/S√°ng"},
        "ai_dup": {"groups": {}, "id": "section-ai", "title": "AI Duplicates"},
        "hash_dup": {"groups": {}, "id": "section-hash", "title": "Hash Duplicates"}
    }

    # 1.1 X·ª≠ l√Ω Quality Log
    for item in quality_log:
        reason = item.get('reason', '').upper()
        real_path = resolve_final_path(item.get('path', ''))
        file_exists = os.path.exists(real_path)
        item_data = {**item, 'path': real_path, 'file_exists': file_exists}

        if "BLUR" in reason:
            categories["blur"]["data"].append(item_data)
            stats["blur"] += 1
        elif "DARK" in reason:
            categories["dark"]["data"].append(item_data)
            stats["dark"] += 1
        elif "BRIGHT" in reason:
            categories["dark"]["data"].append(item_data)
            stats["bright"] += 1
        else:
            categories["blur"]["data"].append(item_data)
            stats["blur"] += 1

    # 1.2 X·ª≠ l√Ω Duplicate Log (FIXED LOGIC HERE)
    for item in duplicate_log:
        reason = item.get('reason', '').upper()
        final_kept = resolve_final_path(item.get('kept_path', ''))
        final_del = resolve_final_path(item.get('del_path', ''))
        
        item_data = {
            **item, 'kept_path': final_kept, 'del_path': final_del,
            'kept_exists': os.path.exists(final_kept),
            'del_exists': os.path.exists(final_del)
        }

        # --- S·ª¨A L·ªñI T·∫†I ƒê√ÇY ---
        # Th√™m ƒëi·ªÅu ki·ªán check "SHA" ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c SHA-256
        is_hash = ("HASH" in reason or "EXACT" in reason or "SHA" in reason)
        cat_key = "hash_dup" if is_hash else "ai_dup"
        # -----------------------
        
        # Gom nh√≥m
        group_key = final_kept
        if group_key not in categories[cat_key]["groups"]:
            categories[cat_key]["groups"][group_key] = {
                "kept_info": {
                    "path": final_kept,
                    "name": item.get('kept_name', os.path.basename(final_kept)),
                    "score": item.get('kept_score', 0),
                    "exists": os.path.exists(final_kept)
                },
                "deleted_items": []
            }
        categories[cat_key]["groups"][group_key]["deleted_items"].append(item_data)
        
        if is_hash: stats["hash_dup"] += 1
        else: stats["ai_dup"] += 1

    stats["total_removed"] = sum(stats.values())
    if total_input == 0: total_input = stats["total_removed"]
    survivors = max(0, total_input - stats["total_removed"])

    # --- 2. RENDER HELPERS ---
    
    def render_lazy_img(src, exists, css_class=""):
        if not exists: return f'<div class="missing-box {css_class}">üö´ Missing</div>'
        placeholder = "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"
        return f'<img src="{placeholder}" data-src="{html.escape(src)}" class="lazy-load {css_class}" loading="lazy" alt="img">'

    def render_quality_card(item, type_badge):
        score = float(item.get('score', 0))
        reason = item.get('reason', 'UNK')
        
        if "BLUR" in reason: badge_color = "#fbbf24"; text_color = "#000"; 
        elif "DARK" in reason: badge_color = "#4b5563"; text_color = "#fff"; 
        elif "BRIGHT" in reason: badge_color = "#f3f4f6"; text_color = "#000"; 
        else: badge_color = "#ef4444"; text_color = "#fff"; 

        img_html = render_lazy_img(item['path'], item['file_exists'], "card-img")
        
        return f"""
        <div class="card fade-in">
            <div class="card-image-container" onclick="openLightbox('{html.escape(item['path'])}')">
                {img_html}
                <div class="stat-badge" style="background: {badge_color}; color: {text_color}">
                    {reason} <span style="opacity:0.8">|</span> {score:.1f}
                </div>
                <div class="card-name-overlay" title="{html.escape(item['name'])}">
                    {html.escape(item['name'])}
                </div>
            </div>
        </div>
        """

    def render_group_row(group_data):
        kept = group_data["kept_info"]
        deleted_list = group_data["deleted_items"]
        
        kept_html = f"""
        <div class="kept-column">
            <div class="status-label kept-label">GI·ªÆ L·∫†I (KEPT)</div>
            <div class="img-wrapper main-img" onclick="openLightbox('{html.escape(kept['path'])}')">
                {render_lazy_img(kept['path'], kept['exists'])}
            </div>
            <div class="meta-info">
                <div class="filename" title="{kept['name']}">{kept['name']}</div>
                <div class="score-bar">Score: <strong style="color: #00ff88">{float(kept['score']):.1f}</strong></div>
            </div>
        </div>
        """

        del_items_html = ""
        for item in deleted_list:
            d_score = float(item.get('del_score', 0))
            diff = float(kept['score']) - d_score
            del_items_html += f"""
            <div class="del-item-card" onclick="openLightbox('{html.escape(item['del_path'])}')">
                <div class="del-img-box">
                    {render_lazy_img(item['del_path'], item['del_exists'])}
                    <div class="overlay-reason">{item['reason']}</div>
                </div>
                <div class="del-meta">
                    <div class="score-mini">{d_score:.1f} <span class="diff">(-{diff:.1f})</span></div>
                </div>
            </div>
            """

        return f"""
        <div class="group-row fade-in">
            {kept_html}
            <div class="arrow-container">
                <div class="arrow-icon">‚ûî</div>
                <div class="clean-count">Cleaned: {len(deleted_list)}</div>
            </div>
            <div class="deleted-column">
                <div class="status-label del-label">ƒê√É X√ìA ({len(deleted_list)})</div>
                <div class="del-grid">{del_items_html}</div>
            </div>
        </div>
        """

    # --- 3. HTML TEMPLATE ---
    html_content = f"""
    <!DOCTYPE html>
    <html lang="vi">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>‚ö° Cleaning Report V3.1</title>
        <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;600;800&family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
        <style>
            :root {{
                --bg: #0f172a; --sidebar: #1e293b; --card-bg: #1e293b;
                --text-main: #f8fafc; --text-sub: #94a3b8;
                --primary: #3b82f6; --success: #10b981; --danger: #ef4444; --warning: #f59e0b;
                --bright: #e2e8f0;
            }}
            * {{ box-sizing: border-box; }}
            body {{ margin: 0; font-family: 'Outfit', sans-serif; background: var(--bg); color: var(--text-main); display: flex; height: 100vh; overflow: hidden; }}
            
            .sidebar {{ width: 260px; background: var(--sidebar); padding: 20px; display: flex; flex-direction: column; border-right: 1px solid rgba(255,255,255,0.05); z-index: 10; }}
            .logo {{ font-size: 1.5rem; font-weight: 800; background: linear-gradient(45deg, var(--primary), var(--success)); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 30px; }}
            .nav-item {{ padding: 12px; border-radius: 8px; cursor: pointer; color: var(--text-sub); display: flex; justify-content: space-between; margin-bottom: 5px; transition: 0.2s; }}
            .nav-item:hover, .nav-item.active {{ background: rgba(255,255,255,0.05); color: #fff; }}
            .nav-item.active {{ border-left: 3px solid var(--primary); background: linear-gradient(90deg, rgba(59,130,246,0.1), transparent); }}
            .badge {{ background: rgba(255,255,255,0.1); padding: 2px 8px; border-radius: 10px; font-size: 0.75rem; }}

            .main {{ flex: 1; overflow-y: auto; padding: 0; position: relative; scroll-behavior: smooth; }}
            .section {{ display: none; padding: 40px; }}
            .section.active {{ display: block; animation: fadeIn 0.3s ease; }}

            .stats-grid {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin-top: 20px; }}
            .stat-box {{ background: var(--card-bg); padding: 20px; border-radius: 16px; border: 1px solid rgba(255,255,255,0.05); text-align: center; }}
            .stat-box.big {{ grid-column: span 2; background: linear-gradient(135deg, rgba(59,130,246,0.1), rgba(16,185,129,0.1)); border: 1px solid rgba(59,130,246,0.2); }}
            .stat-num {{ font-size: 2.5rem; font-weight: 800; margin-bottom: 5px; color: var(--text-main); }}
            .stat-label {{ color: var(--text-sub); font-size: 0.8rem; text-transform: uppercase; letter-spacing: 1px; }}

            .grid-container {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 20px; }}
            .card {{ background: rgba(255,255,255,0.03); border-radius: 12px; overflow: hidden; position: relative; }}
            .card-image-container {{ height: 220px; position: relative; background: #000; cursor: zoom-in; }}
            
            .stat-badge {{ 
                position: absolute; top: 10px; left: 10px; z-index: 5;
                padding: 4px 10px; border-radius: 6px; 
                font-size: 0.75rem; font-weight: 800; 
                box-shadow: 0 4px 10px rgba(0,0,0,0.5);
                font-family: 'JetBrains Mono', monospace;
            }}
            .card-name-overlay {{
                position: absolute; bottom: 0; left: 0; width: 100%;
                background: linear-gradient(to top, rgba(0,0,0,0.9), transparent);
                color: white; padding: 30px 10px 10px 10px;
                font-size: 0.8rem; font-weight: 600;
                white-space: nowrap; overflow: hidden; text-overflow: ellipsis;
            }}

            .group-row {{ display: flex; background: rgba(255,255,255,0.03); border: 1px solid rgba(255,255,255,0.05); border-radius: 16px; padding: 20px; margin-bottom: 30px; gap: 20px; align-items: stretch; }}
            .kept-column {{ width: 250px; display: flex; flex-direction: column; }}
            .deleted-column {{ flex: 1; display: flex; flex-direction: column; background: rgba(0,0,0,0.2); border-radius: 12px; padding: 15px; }}
            .arrow-container {{ display: flex; flex-direction: column; justify-content: center; align-items: center; width: 50px; color: var(--text-sub); }}
            
            .img-wrapper.main-img {{ height: 200px; border: 2px solid var(--success); border-radius: 12px; overflow: hidden; margin-bottom: 10px; cursor: zoom-in; }}
            
            .del-grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(100px, 1fr)); gap: 10px; }}
            .del-item-card {{ background: rgba(255,255,255,0.05); border-radius: 8px; overflow: hidden; cursor: zoom-in; transition: transform 0.2s; }}
            .del-item-card:hover {{ transform: translateY(-3px); }}
            .del-img-box {{ height: 80px; position: relative; }}
            .overlay-reason {{ position: absolute; bottom: 0; width: 100%; background: rgba(239, 68, 68, 0.9); color: white; font-size: 0.6rem; text-align: center; }}
            .del-meta {{ padding: 5px; text-align: center; }}
            .score-mini {{ font-size: 0.65rem; color: var(--text-sub); }}
            .diff {{ color: var(--danger); font-weight: bold; }}

            img.lazy-load {{ opacity: 0; transition: opacity 0.5s; width: 100%; height: 100%; object-fit: cover; }}
            img.lazy-load.loaded {{ opacity: 1; }}
            .status-label {{ font-size: 0.7rem; font-weight: 800; padding: 4px 8px; border-radius: 4px; margin-bottom: 10px; display: inline-block; }}
            .kept-label {{ background: rgba(16, 185, 129, 0.2); color: var(--success); }}
            .del-label {{ background: rgba(239, 68, 68, 0.2); color: var(--danger); }}
            .meta-info .filename {{ font-size: 0.8rem; font-weight: 600; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; }}
            
            #lightbox {{ position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.95); z-index: 9999; display: none; justify-content: center; align-items: center; }}
            #lightbox img {{ max-width: 95%; max-height: 95%; box-shadow: 0 0 30px rgba(0,0,0,0.5); }}
            .close-lb {{ position: absolute; top: 20px; right: 30px; font-size: 3rem; color: white; cursor: pointer; }}

            @keyframes fadeIn {{ from {{ opacity: 0; transform: translateY(10px); }} to {{ opacity: 1; transform: translateY(0); }} }}
        </style>
    </head>
    <body>

        <div class="sidebar">
            <div class="logo">üöÄ CLEANER V3.1</div>
            <div class="nav-item active" onclick="switchTab('section-summary', this)">
                <span>Overview</span>
            </div>
            <div style="height:1px; background:rgba(255,255,255,0.1); margin:15px 0;"></div>
            <div class="nav-item" onclick="switchTab('section-blur', this)">
                <span>Blurry</span> <span class="badge" style="color:var(--warning)">{len(categories['blur']['data'])}</span>
            </div>
            <div class="nav-item" onclick="switchTab('section-dark', this)">
                <span>Dark/Bright</span> <span class="badge" style="color:var(--bright)">{len(categories['dark']['data'])}</span>
            </div>
            <div style="height:1px; background:rgba(255,255,255,0.1); margin:15px 0;"></div>
            <div class="nav-item" onclick="switchTab('section-ai', this)">
                <span>AI Duplicates</span> <span class="badge" style="color:var(--primary)">{stats['ai_dup']}</span>
            </div>
            <div class="nav-item" onclick="switchTab('section-hash', this)">
                <span>Hash Duplicates</span> <span class="badge" style="color:var(--success)">{stats['hash_dup']}</span>
            </div>
        </div>

        <div class="main">
            <div id="section-summary" class="section active">
                <h1 style="color:var(--primary)">Processing Statistics</h1>
                
                <div class="stats-grid">
                    <div class="stat-box big">
                        <div class="stat-num" style="color: var(--primary)">{total_input}</div>
                        <div class="stat-label">Total Files Input</div>
                    </div>
                    <div class="stat-box big">
                        <div class="stat-num" style="color: var(--success)">{survivors}</div>
                        <div class="stat-label">Clean Files Remaining</div>
                    </div>
                    
                    <div class="stat-box">
                        <div class="stat-num" style="color: var(--warning)">{stats['blur']}</div>
                        <div class="stat-label">Blurry Removed</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-num" style="color: var(--danger)">{stats['dark']}</div>
                        <div class="stat-label">Too Dark</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-num" style="color: var(--bright)">{stats['bright']}</div>
                        <div class="stat-label">Too Bright</div>
                    </div>
                    <div class="stat-box" style="background:rgba(59,130,246,0.05)">
                         <div class="stat-num" style="font-size: 1.5rem; margin-top:10px">{stats['total_removed']}</div>
                         <div class="stat-label">Total Removed</div>
                    </div>

                    <div class="stat-box big" style="background:rgba(255,255,255,0.02)">
                        <div class="stat-num" style="color: var(--text-sub)">{stats['hash_dup']}</div>
                        <div class="stat-label">Exact Hash Duplicates</div>
                    </div>
                    <div class="stat-box big" style="background:rgba(255,255,255,0.02)">
                        <div class="stat-num" style="color: var(--text-sub)">{stats['ai_dup']}</div>
                        <div class="stat-label">AI Semantic Duplicates</div>
                    </div>
                </div>
            </div>

            <div id="section-blur" class="section">
                <h2>Blurry Images</h2>
                <div class="grid-container">
                    {"".join([render_quality_card(i, "BLUR") for i in categories['blur']['data']])}
                </div>
            </div>

            <div id="section-dark" class="section">
                <h2>Dark / Bright Images</h2>
                <div class="grid-container">
                    {"".join([render_quality_card(i, "DARK") for i in categories['dark']['data']])}
                </div>
            </div>

            <div id="section-ai" class="section">
                <h2>AI Semantic Duplicates</h2>
                <p style="color:var(--text-sub)">AI-detected similar images. The best version is kept.</p>
                {"".join([render_group_row(g) for g in categories['ai_dup']['groups'].values()])}
            </div>

            <div id="section-hash" class="section">
                <h2>Hash Exact Duplicates</h2>
                <p style="color:var(--text-sub)">Bit-by-bit exact copies.</p>
                {"".join([render_group_row(g) for g in categories['hash_dup']['groups'].values()])}
            </div>
        </div>

        <div id="lightbox" onclick="this.style.display='none'">
            <span class="close-lb">&times;</span>
            <img id="lb-img" src="">
        </div>

        <script>
            function switchTab(id, el) {{
                document.querySelectorAll('.section').forEach(s => s.classList.remove('active'));
                document.getElementById(id).classList.add('active');
                document.querySelectorAll('.nav-item').forEach(n => n.classList.remove('active'));
                el.classList.add('active');
                setTimeout(observeImages, 100);
            }}

            function openLightbox(src) {{
                document.getElementById('lb-img').src = src;
                document.getElementById('lightbox').style.display = 'flex';
            }}

            function observeImages() {{
                const images = document.querySelectorAll('img.lazy-load');
                const observer = new IntersectionObserver((entries, obs) => {{
                    entries.forEach(entry => {{
                        if (entry.isIntersecting) {{
                            const img = entry.target;
                            img.src = img.dataset.src;
                            img.classList.add('loaded');
                            obs.unobserve(img);
                        }}
                    }});
                }}, {{ rootMargin: "200px" }});
                images.forEach(img => observer.observe(img));
            }}
            document.addEventListener('DOMContentLoaded', observeImages);
        </script>
    </body>
    </html>
    """
    
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(html_content)
        print(f"‚úÖ B√°o c√°o V3.1 (Fixed SHA Logic) ƒë√£ xong: {os.path.abspath(output_file)}")
    except Exception as e:
        print(f"‚ùå L·ªói ghi file: {e}")
# ================= MAIN =================
def main():
    start_time = time.time()
    setup_folders()

    # B∆∞·ªõc 0: Load ·∫£nh t·ª´ INPUT
    all_images = get_image_paths()
    if not all_images: 
        print("‚ùå Kh√¥ng ƒë·ªß ·∫£nh - d·ª´ng ch∆∞∆°ng tr√¨nh")
        return
    print(f"üîç T·ªïng ·∫£nh ƒë·∫ßu v√†o: {len(all_images)}")

    # B∆∞·ªõc 1: L·ªçc ch·∫•t l∆∞·ª£ng ·∫£nh
    clean_images, quality_log = scan_and_filter_quality(all_images_path=all_images)
    print(f"üìâ ƒê√£ l·ªçc ƒë∆∞·ª£c: {len(all_images) - len(clean_images)} ·∫£nh k√©m ch·∫•t l∆∞·ª£ng")

    # B∆∞·ªõc 2: Hashing
    deleted_hashing, duplicate_log = find_duplicates_by_hashing(clean_images)
    clean_images = [img for img in clean_images if img not in deleted_hashing]
    print(f"üìâ ƒê√£ l·ªçc ƒë∆∞·ª£c: {len(clean_images) - len(deleted_hashing)} b·∫±ng Hashings\n")

    # B∆∞·ªõc 3: Deep Learning
    # features: C√°c ƒë·∫∑c tr∆∞ng c·ªßa ·∫£nh
    # paths: ƒê∆∞·ªùng d·∫´n ·∫£nh tr√πng v·ªõi ƒë·∫∑c tr∆∞ng
    features, paths = extract_features(clean_images)

    # B∆∞·ªõc 4 & 5: FAISS Clustering
    if features is not None and len(paths) > 0:
        deleted_faiss_count = cluster_and_filter_faiss(features, paths, duplicate_log)
        print(f"üìâ ƒê√£ l·ªçc th√™m {deleted_faiss_count} ·∫£nh tr√πng b·∫±ng AI.\n")
    else:
        print("‚ö†Ô∏è Kh√¥ng c√≥ feature n√†o ƒë·ªÉ ch·∫°y FAISS.")

    # B∆∞·ªõc 6: Report
    generate_html_report(
    duplicate_log, 
    quality_log, 
    os.path.join(OUTPUT_BASE, REPORT_FILE), 
    total_input=len(all_images)  # <--- Th√™m tham s·ªë n√†y v√†o
)
    
    log_data = {
        "quality_log": quality_log,
        "duplicate_log": duplicate_log,
        "stats": {
            "total_input": len(all_images),
            "clean_after_quality": len(clean_images) if 'clean_images' in locals() else 0,
        }
    }
    with open(os.path.join(OUTPUT_BASE, "cleaning_log.json"), "w", encoding="utf-8") as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)
        print("‚úÖ ƒê√£ l∆∞u file log th√¥ (JSON).")
        
    print(f'\nüèÅ Th·ªùi gian ch·∫°y: {time.time() - start_time:.2f} gi√¢y')

if __name__ == "__main__":
    # --- THI·∫æT L·∫¨P QUAN TR·ªåNG CHO MACOS/LINUX ---
    try:
        # Tr√°nh l·ªói malloc error.
        # Thay v√¨ d√πng fork m·∫∑c ƒë·ªãnh -> chuy·ªÉn qua d√πng spawn
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        print("Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi qua spawn")
        pass
    
    # D√†nh cho Chip M seri:
    # N·∫øu g·∫∑p ph√©p t√≠nh n√†o m√† GPU (MPS) kh√¥ng l√†m ƒë∆∞·ª£c, kh√¥ng b√°o l·ªói. H√£y chuy·ªÉn ph√©p t√≠nh ƒë√≥ v·ªÅ CPU ƒë·ªÉ x·ª≠ l√Ω, r·ªìi sau ƒë√≥ l·∫°i d√πng GPU ti·∫øp.
    if torch.backends.mps.is_available():
        os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

    main()
